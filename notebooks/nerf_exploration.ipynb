{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"NeRF Exploration: Two-View Reconstruction of Pollen Grains\"\n",
        "author: \"Nils Fahrni, Etienne Roulet\"\n",
        "date: \"2025-03-28\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    code-fold: true\n",
        "    code-line-numbers: true\n",
        "    embed-resources: true\n",
        "    self-contained-math: true\n",
        "  ipynb: default\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "# Abstract\n",
        "\n",
        "abstract desc\n",
        "\n",
        "# 1 Introduction\n",
        "\n",
        "Text here\n",
        "\n",
        "**Key questions**\n",
        "\n",
        "- Text\n",
        "- Text\n",
        "- Text\n",
        "\n",
        "\n",
        "# 2 Environment check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Findings\n",
        "\n",
        "- list findings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4 More complex NeRF exploration\n",
        "\n",
        "## Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SYS] Using device: cuda\n",
            "[DATA] Loaded sample #86 → images: torch.Size([1, 1024, 1024]),torch.Size([1, 1024, 1024]); points: torch.Size([4000, 3]); rotations (rad): [42.67660903930664, 57.744712829589844, 296.34222412109375]; voxels: torch.Size([128, 128, 128])\n",
            "[DATA] Image dimensions: 1024x1024\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TRAIN] Starting training ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   2%|▏         | 208/10000 [00:03<02:31, 64.63iter/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 200: total=0.0545, photo=0.0183, sil=0.0355, shape=0.0928, dens=0.0029, smooth=0.0005\n",
            "[TRAIN] ==> New best model saved.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|▍         | 411/10000 [00:06<02:31, 63.09iter/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 400: total=0.0330, photo=0.0104, sil=0.0212, shape=0.1654, dens=0.0046, smooth=0.0033\n",
            "[TRAIN] ==> New best model saved.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|▌         | 597/10000 [00:09<02:28, 63.28iter/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 858\u001b[39m\n\u001b[32m    856\u001b[39m \u001b[38;5;66;03m# 11) Initialize NeRF & Train (unchanged)\u001b[39;00m\n\u001b[32m    857\u001b[39m model = NeRF(D=\u001b[32m6\u001b[39m, W=\u001b[32m128\u001b[39m, L=\u001b[32m4\u001b[39m).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m858\u001b[39m model = \u001b[43mtrain_nerf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrays_o_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrays_d_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_pixels_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnear\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfar\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigma_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdebug_renders\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;66;03m# 12) Extract mesh & (optional) compare to gt_points…\u001b[39;00m\n\u001b[32m    875\u001b[39m pred_mesh = extract_3d_from_nerf(\n\u001b[32m    876\u001b[39m     model, resolution=\u001b[32m256\u001b[39m, bound=\u001b[32m1.0\u001b[39m, sigma_scale=\u001b[32m1.0\u001b[39m, device=device\n\u001b[32m    877\u001b[39m )\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 655\u001b[39m, in \u001b[36mtrain_nerf\u001b[39m\u001b[34m(model, rays_o_all, rays_d_all, target_pixels_all, mask_all, image_shape, num_iterations, device, near, far, sigma_scale, debug_interval, out_dir)\u001b[39m\n\u001b[32m    647\u001b[39m sil_loss_val = silhouette_loss(alpha_map, mask_batch)\n\u001b[32m    648\u001b[39m shape_loss_val = spherical_prior_loss(\n\u001b[32m    649\u001b[39m     model,\n\u001b[32m    650\u001b[39m     bound=\u001b[32m1.0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    653\u001b[39m     device=device,\n\u001b[32m    654\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m dens_loss_val = \u001b[43mforeground_density_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_density\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\n\u001b[32m    657\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m smooth_loss_val = smoothness_prior_loss(\n\u001b[32m    659\u001b[39m     model, bound=\u001b[32m1.0\u001b[39m, offset=\u001b[32m0.01\u001b[39m, sigma_scale=sigma_scale, device=device\n\u001b[32m    660\u001b[39m )\n\u001b[32m    662\u001b[39m total_loss = (\n\u001b[32m    663\u001b[39m     photo_loss\n\u001b[32m    664\u001b[39m     + lambda_sil * sil_loss_val\n\u001b[32m   (...)\u001b[39m\u001b[32m    667\u001b[39m     + lambda_smooth * smooth_loss_val\n\u001b[32m    668\u001b[39m )\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 153\u001b[39m, in \u001b[36mforeground_density_loss\u001b[39m\u001b[34m(alpha_map, mask, target_density)\u001b[39m\n\u001b[32m    151\u001b[39m fg_mask = mask > \u001b[32m0.5\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.sum(fg_mask) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.mean(torch.clamp(\u001b[43mtarget_density\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfg_mask\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mmin\u001b[39m=\u001b[32m0.0\u001b[39m))\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(\u001b[32m0.0\u001b[39m, device=alpha_map.device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\super\\Documents\\GitHub\\sequoia\\.venv\\Lib\\site-packages\\torch\\_tensor.py:33\u001b[39m, in \u001b[36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(f):\n\u001b[32m     31\u001b[39m     assigned = functools.WRAPPER_ASSIGNMENTS\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;129m@functools\u001b[39m.wraps(f, assigned=assigned)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m     35\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[32m     37\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "from scipy.spatial import cKDTree\n",
        "from skimage.measure import marching_cubes\n",
        "import trimesh\n",
        "\n",
        "# If you have the data package\n",
        "sys.path.append(\"..\")\n",
        "try:\n",
        "    from data.pollen_dataset import PollenDataset, get_train_test_split\n",
        "except ImportError:\n",
        "    # Fallback if not available\n",
        "    PollenDataset = None\n",
        "    get_train_test_split = None\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 1. Positional Encoding (Reduced Frequencies)\n",
        "################################################################################\n",
        "def positional_encoding(x, L=4):\n",
        "    \"\"\"\n",
        "    Encode coordinates x with sine/cosine functions at increasing frequencies.\n",
        "    We use L=4 here (fewer than the classic L=10) to reduce high-frequency overfitting.\n",
        "    \"\"\"\n",
        "    out = [x]\n",
        "    for i in range(L):\n",
        "        for fn in (torch.sin, torch.cos):\n",
        "            out.append(fn((2.0**i) * np.pi * x))\n",
        "    return torch.cat(out, dim=-1)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 2. NeRF Model with Reduced Positional Encoding\n",
        "################################################################################\n",
        "class NeRF(nn.Module):\n",
        "    def __init__(self, D=6, W=128, L=4):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            D: Number of hidden layers\n",
        "            W: Number of hidden units per layer\n",
        "            L: Positional encoding frequency levels\n",
        "        \"\"\"\n",
        "        super(NeRF, self).__init__()\n",
        "        self.L = L\n",
        "        in_channels = 3 * (2 * L + 1)  # 3 coords * (2L + 1)\n",
        "\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(in_channels, W))\n",
        "        for _ in range(D - 1):\n",
        "            layers.append(nn.Linear(W, W))\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.output_layer = nn.Linear(W, 4)\n",
        "\n",
        "        # Initialize sigma bias to something non-zero\n",
        "        with torch.no_grad():\n",
        "            self.output_layer.bias[3] = 0.1\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: x is (N, 3), output is (N, 4) => [R, G, B, sigma].\n",
        "        \"\"\"\n",
        "        x_enc = positional_encoding(x, self.L)\n",
        "        h = x_enc\n",
        "        for layer in self.layers:\n",
        "            h = torch.relu(layer(h))\n",
        "        return self.output_layer(h)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 3. Render Rays (RGB + Alpha)\n",
        "################################################################################\n",
        "def render_rays(\n",
        "    model, rays_o, rays_d, near=0.5, far=1.5, N_samples=128, sigma_scale=1.0\n",
        "):\n",
        "    \"\"\"\n",
        "    Volumetric rendering for a batch of rays:\n",
        "      - Sample points along each ray\n",
        "      - Query MLP for color (rgb) and density (sigma)\n",
        "      - Composite color and alpha\n",
        "    \"\"\"\n",
        "    device = rays_o.device\n",
        "    z_vals = torch.linspace(near, far, N_samples, device=device)\n",
        "\n",
        "    pts = (\n",
        "        rays_o[:, None, :] + rays_d[:, None, :] * z_vals[None, :, None]\n",
        "    )  # (B, N_samples, 3)\n",
        "    pts_flat = pts.reshape(-1, 3)\n",
        "\n",
        "    raw = model(pts_flat).reshape(pts.shape[0], N_samples, 4)\n",
        "    rgb = torch.sigmoid(raw[..., :3])\n",
        "    sigma = torch.relu(raw[..., 3]) * sigma_scale\n",
        "\n",
        "    deltas = z_vals[1:] - z_vals[:-1]\n",
        "    deltas = torch.cat([deltas, torch.tensor([1e10], device=device)])\n",
        "    deltas = deltas[None, :].expand(sigma.shape)\n",
        "\n",
        "    alpha = 1.0 - torch.exp(-sigma * deltas)\n",
        "    T = torch.cumprod(\n",
        "        torch.cat(\n",
        "            [torch.ones((sigma.shape[0], 1), device=device), 1.0 - alpha + 1e-10],\n",
        "            dim=-1,\n",
        "        ),\n",
        "        dim=-1,\n",
        "    )[:, :-1]\n",
        "    weights = alpha * T\n",
        "\n",
        "    rgb_map = torch.sum(weights[..., None] * rgb, dim=1)\n",
        "    alpha_map = torch.sum(weights, dim=1)\n",
        "    return rgb_map, alpha_map\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 4. Losses: Silhouette, Spherical Prior, etc.\n",
        "################################################################################\n",
        "def silhouette_loss(alpha_map, mask):\n",
        "    return torch.mean((alpha_map - mask) ** 2)\n",
        "\n",
        "\n",
        "def spherical_prior_loss(\n",
        "    model, num_samples=2000, bound=1.0, desired_radius=0.6, sigma_scale=2.0, device=None\n",
        "):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    coords = torch.rand(num_samples, 3, device=device) * (2 * bound) - bound\n",
        "\n",
        "    raw = model(coords)\n",
        "    sigma = torch.relu(raw[..., 3]) * sigma_scale\n",
        "    dists = torch.norm(coords, dim=1)\n",
        "    # Encourage high sigma near the desired radius\n",
        "    loss = torch.mean(sigma * (dists - desired_radius) ** 2)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def foreground_density_loss(alpha_map, mask, target_density=1.0):\n",
        "    eps = 1e-6\n",
        "    D = -torch.log(1.0 - alpha_map + eps)\n",
        "    fg_mask = mask > 0.5\n",
        "    if torch.sum(fg_mask) > 0:\n",
        "        return torch.mean(torch.clamp(target_density - D[fg_mask], min=0.0))\n",
        "    else:\n",
        "        return torch.tensor(0.0, device=alpha_map.device)\n",
        "\n",
        "\n",
        "def smoothness_prior_loss(\n",
        "    model, num_samples=2000, bound=1.0, offset=0.01, sigma_scale=2.0, device=None\n",
        "):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    coords = torch.rand(num_samples, 3, device=device) * (2 * bound) - bound\n",
        "\n",
        "    raw_center = model(coords)\n",
        "    sigma_center = torch.relu(raw_center[..., 3]) * sigma_scale\n",
        "\n",
        "    offsets = torch.tensor(\n",
        "        [\n",
        "            [offset, 0, 0],\n",
        "            [-offset, 0, 0],\n",
        "            [0, offset, 0],\n",
        "            [0, -offset, 0],\n",
        "            [0, 0, offset],\n",
        "            [0, 0, -offset],\n",
        "        ],\n",
        "        device=device,\n",
        "    ).float()\n",
        "\n",
        "    total_diff = 0.0\n",
        "    for off in offsets:\n",
        "        neighbor_coords = coords + off\n",
        "        raw_neighbor = model(neighbor_coords)\n",
        "        sigma_neighbor = torch.relu(raw_neighbor[..., 3]) * sigma_scale\n",
        "        total_diff += torch.mean((sigma_center - sigma_neighbor) ** 2)\n",
        "\n",
        "    return total_diff / offsets.shape[0]\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 5. Ray Generation (Two Orthogonal Views)\n",
        "################################################################################\n",
        "import torch\n",
        "from trimesh.transformations import euler_matrix\n",
        "\n",
        "\n",
        "def get_rays(H, W, focal=300.0):\n",
        "    \"\"\"\n",
        "    Returns canonical (unrotated) front‐and‐side rays:\n",
        "      rays_o_front, rays_d_front, rays_o_side, rays_d_side\n",
        "      all as (H*W, 3) tensors.\n",
        "    \"\"\"\n",
        "    i, j = torch.meshgrid(\n",
        "        torch.linspace(0, W - 1, W),\n",
        "        torch.linspace(0, H - 1, H),\n",
        "        indexing=\"xy\",\n",
        "    )\n",
        "    # front\n",
        "    dirs_f = torch.stack(\n",
        "        [(i - W / 2.0) / focal, -(j - H / 2.0) / focal, -torch.ones_like(i)],\n",
        "        dim=-1,\n",
        "    )\n",
        "    rays_d_f = dirs_f / torch.norm(dirs_f, dim=-1, keepdim=True)\n",
        "    rays_o_f = torch.zeros_like(rays_d_f)\n",
        "\n",
        "    # side\n",
        "    dirs_s = torch.stack(\n",
        "        [torch.ones_like(i), -(j - H / 2.0) / focal, -(i - W / 2.0) / focal],\n",
        "        dim=-1,\n",
        "    )\n",
        "    rays_d_s = dirs_s / torch.norm(dirs_s, dim=-1, keepdim=True)\n",
        "    rays_o_s = torch.zeros_like(rays_d_s)\n",
        "    rays_o_s[..., 0] = -1.5\n",
        "\n",
        "    return (\n",
        "        rays_o_f.reshape(-1, 3),\n",
        "        rays_d_f.reshape(-1, 3),\n",
        "        rays_o_s.reshape(-1, 3),\n",
        "        rays_d_s.reshape(-1, 3),\n",
        "    )\n",
        "\n",
        "\n",
        "def rotate_rays(rays_o, rays_d, euler_angles):\n",
        "    \"\"\"\n",
        "    Apply the sample's rotation (in radians) to both origins and directions.\n",
        "    euler_angles: tensor([rx, ry, rz]) in radians, in 'sxyz' convention.\n",
        "    \"\"\"\n",
        "    # build 4×4 rotation matrix, then extract the 3×3 upper‐left block\n",
        "    R4 = euler_matrix(\n",
        "        float(euler_angles[0]),\n",
        "        float(euler_angles[1]),\n",
        "        float(euler_angles[2]),\n",
        "        \"sxyz\",\n",
        "    )\n",
        "    R = torch.from_numpy(R4[:3, :3]).to(rays_o.device).float()\n",
        "\n",
        "    # rotate origins & directions\n",
        "    ro = (R @ rays_o.T).T\n",
        "    rd = (R @ rays_d.T).T\n",
        "    return ro, rd\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 6. Weighted Ray Sampling (Edges + Foreground)\n",
        "################################################################################\n",
        "def sample_rays_weighted(rays_o, rays_d, rgb, mask, original_shape, batch_size=1024):\n",
        "    \"\"\"\n",
        "    Sample rays with higher probability at silhouette edges and foreground.\n",
        "    \"\"\"\n",
        "    H, W = original_shape\n",
        "    total_pixels = mask.shape[0]\n",
        "    pixels_per_view = H * W\n",
        "\n",
        "    if total_pixels == 2 * pixels_per_view:\n",
        "        # Two views\n",
        "        weights_list = []\n",
        "        for view_idx in range(2):\n",
        "            start_idx = view_idx * pixels_per_view\n",
        "            end_idx = start_idx + pixels_per_view\n",
        "            view_mask = mask[start_idx:end_idx]\n",
        "            mask_2d = view_mask.reshape(H, W)\n",
        "\n",
        "            kernel = (\n",
        "                torch.tensor(\n",
        "                    [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], device=mask.device\n",
        "                ).float()\n",
        "                / 8\n",
        "            )\n",
        "            kernel = kernel.reshape(1, 1, 3, 3)\n",
        "\n",
        "            edges = torch.abs(\n",
        "                torch.nn.functional.conv2d(\n",
        "                    mask_2d.reshape(1, 1, H, W), kernel, padding=1\n",
        "                )\n",
        "            ).reshape(H, W)\n",
        "            edge_weights = edges.reshape(-1) + 0.1\n",
        "            fg_weights = (view_mask > 0.5).float() * 2.0\n",
        "            weights = edge_weights + fg_weights\n",
        "            weights_list.append(weights)\n",
        "        weights = torch.cat(weights_list)\n",
        "    else:\n",
        "        # Single view fallback\n",
        "        mask_2d = mask.reshape(H, W)\n",
        "        kernel = (\n",
        "            torch.tensor(\n",
        "                [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], device=mask.device\n",
        "            ).float()\n",
        "            / 8\n",
        "        )\n",
        "        kernel = kernel.reshape(1, 1, 3, 3)\n",
        "        edges = torch.abs(\n",
        "            torch.nn.functional.conv2d(mask_2d.reshape(1, 1, H, W), kernel, padding=1)\n",
        "        ).reshape(H, W)\n",
        "        edge_weights = edges.reshape(-1) + 0.1\n",
        "        fg_weights = (mask > 0.5).float() * 2.0\n",
        "        weights = edge_weights + fg_weights\n",
        "\n",
        "    p = weights / weights.sum()\n",
        "    idx = torch.multinomial(p, batch_size, replacement=True)\n",
        "\n",
        "    return rays_o[idx], rays_d[idx], rgb[idx], mask[idx]\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 7. Debug Rendering (with Extra Mask Comparison)\n",
        "################################################################################\n",
        "@torch.no_grad()\n",
        "def debug_render(\n",
        "    model,\n",
        "    rays_o,\n",
        "    rays_d,\n",
        "    H,\n",
        "    W,\n",
        "    near=0.5,\n",
        "    far=1.5,\n",
        "    sigma_scale=2.0,\n",
        "    N_samples=64,\n",
        "    device=None,\n",
        "    title_prefix=\"debug\",\n",
        "    iteration=0,\n",
        "    out_dir=\"debug_renders\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Render the entire image (front or side) for debugging.\n",
        "    Saves color, alpha, and (optionally) a side-by-side mask comparison.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = rays_o.device\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    B = rays_o.shape[0]\n",
        "    chunk_size = 2048\n",
        "    all_rgb = []\n",
        "    all_alpha = []\n",
        "\n",
        "    for start in range(0, B, chunk_size):\n",
        "        rgb_chunk, alpha_chunk = render_rays(\n",
        "            model,\n",
        "            rays_o[start : start + chunk_size],\n",
        "            rays_d[start : start + chunk_size],\n",
        "            near=near,\n",
        "            far=far,\n",
        "            sigma_scale=sigma_scale,\n",
        "            N_samples=N_samples,\n",
        "        )\n",
        "        all_rgb.append(rgb_chunk)\n",
        "        all_alpha.append(alpha_chunk)\n",
        "\n",
        "    rgb_full = torch.cat(all_rgb, dim=0).reshape(H, W, 3).cpu().numpy()\n",
        "    alpha_full = torch.cat(all_alpha, dim=0).reshape(H, W).cpu().numpy()\n",
        "\n",
        "    # 1. Save the RGB image\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(np.clip(rgb_full, 0, 1))\n",
        "    plt.title(f\"{title_prefix}_rgb_iter_{iteration}\")\n",
        "    plt.axis(\"off\")\n",
        "    rgb_path = os.path.join(out_dir, f\"{title_prefix}_rgb_iter_{iteration}.png\")\n",
        "    plt.savefig(rgb_path)\n",
        "    plt.close()\n",
        "\n",
        "    # 2. Save the alpha map\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(alpha_full, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    plt.title(f\"{title_prefix}_alpha_iter_{iteration}\")\n",
        "    plt.axis(\"off\")\n",
        "    alpha_path = os.path.join(out_dir, f\"{title_prefix}_alpha_iter_{iteration}.png\")\n",
        "    plt.savefig(alpha_path)\n",
        "    plt.close()\n",
        "\n",
        "    print(\n",
        "        f\"[DEBUG RENDER] Saved {title_prefix} images at iter {iteration} in {out_dir}/\"\n",
        "    )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def debug_compare_mask_and_alpha(\n",
        "    model,\n",
        "    rays_o,\n",
        "    rays_d,\n",
        "    mask,\n",
        "    H,\n",
        "    W,\n",
        "    near=0.5,\n",
        "    far=1.5,\n",
        "    sigma_scale=2.0,\n",
        "    N_samples=64,\n",
        "    device=None,\n",
        "    title_prefix=\"debug\",\n",
        "    iteration=0,\n",
        "    out_dir=\"debug_renders\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Render alpha for all rays, then show a side-by-side comparison\n",
        "    of predicted alpha vs. ground-truth mask for debugging.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = rays_o.device\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Render alpha\n",
        "    B = rays_o.shape[0]\n",
        "    chunk_size = 2048\n",
        "    all_alpha = []\n",
        "    for start in range(0, B, chunk_size):\n",
        "        _, alpha_chunk = render_rays(\n",
        "            model,\n",
        "            rays_o[start : start + chunk_size],\n",
        "            rays_d[start : start + chunk_size],\n",
        "            near=near,\n",
        "            far=far,\n",
        "            sigma_scale=sigma_scale,\n",
        "            N_samples=N_samples,\n",
        "        )\n",
        "        all_alpha.append(alpha_chunk)\n",
        "    alpha_full = torch.cat(all_alpha, dim=0).reshape(H, W).cpu().numpy()\n",
        "\n",
        "    # Reshape the ground-truth mask as well\n",
        "    mask_gt = mask.reshape(H, W).cpu().numpy()\n",
        "\n",
        "    # Plot side-by-side\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(mask_gt, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    plt.title(f\"{title_prefix} GT Mask (iter={iteration})\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(alpha_full, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    plt.title(f\"{title_prefix} Alpha (iter={iteration})\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    compare_path = os.path.join(\n",
        "        out_dir, f\"{title_prefix}_mask_vs_alpha_iter_{iteration}.png\"\n",
        "    )\n",
        "    plt.savefig(compare_path)\n",
        "    plt.close()\n",
        "\n",
        "    print(\n",
        "        f\"[DEBUG] Saved mask-vs-alpha comparison for {title_prefix} at iter {iteration} in {out_dir}/\"\n",
        "    )\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 8. 3D Extraction via Marching Cubes\n",
        "################################################################################\n",
        "def extract_3d_from_nerf(\n",
        "    model, resolution=128, bound=1.0, sigma_scale=2.0, device=None\n",
        "):\n",
        "    print(\"\\n[EXTRACT 3D] Running marching cubes...\")\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    model.eval()\n",
        "    coords = (\n",
        "        torch.stack(\n",
        "            torch.meshgrid(\n",
        "                torch.linspace(-bound, bound, resolution),\n",
        "                torch.linspace(-bound, bound, resolution),\n",
        "                torch.linspace(-bound, bound, resolution),\n",
        "                indexing=\"ij\",\n",
        "            ),\n",
        "            dim=-1,\n",
        "        )\n",
        "        .reshape(-1, 3)\n",
        "        .to(device)\n",
        "    )\n",
        "\n",
        "    sigmas = []\n",
        "    chunk = 4096\n",
        "    with torch.no_grad():\n",
        "        for start in range(0, coords.shape[0], chunk):\n",
        "            out = model(coords[start : start + chunk])\n",
        "            sigma_part = torch.relu(out[..., 3]) * sigma_scale\n",
        "            sigmas.append(sigma_part.cpu())\n",
        "    sigma_volume = torch.cat(sigmas).reshape(resolution, resolution, resolution).numpy()\n",
        "\n",
        "    vol_min, vol_max = sigma_volume.min(), sigma_volume.max()\n",
        "    vol_mean, vol_std = sigma_volume.mean(), sigma_volume.std()\n",
        "    print(\n",
        "        f\"  Sigma volume stats: min={vol_min:.4f}, max={vol_max:.4f}, mean={vol_mean:.4f}, std={vol_std:.4f}\"\n",
        "    )\n",
        "\n",
        "    level = vol_mean + 0.3 * vol_std\n",
        "    if (level <= vol_min) or (level >= vol_max):\n",
        "        level = vol_mean\n",
        "    print(f\"  Using iso-level={level:.4f}\")\n",
        "\n",
        "    try:\n",
        "        verts, faces, normals, _ = marching_cubes(sigma_volume, level=level)\n",
        "        # Rescale to [-bound, bound]\n",
        "        verts = (verts / resolution) * (2.0 * bound) - bound\n",
        "        mesh = trimesh.Trimesh(vertices=verts, faces=faces, normals=normals)\n",
        "        mesh.export(\"nerf_reconstruction.stl\")\n",
        "        print(\"  --> Saved mesh to nerf_reconstruction.stl\")\n",
        "        return mesh\n",
        "    except Exception as e:\n",
        "        print(\"  Marching cubes error:\", e)\n",
        "        print(\"  Trying fallback iso-level...\")\n",
        "        try:\n",
        "            fallback_level = vol_mean + 0.25 * vol_std\n",
        "            verts, faces, normals, _ = marching_cubes(\n",
        "                sigma_volume, level=fallback_level\n",
        "            )\n",
        "            verts = (verts / resolution) * (2.0 * bound) - bound\n",
        "            mesh = trimesh.Trimesh(vertices=verts, faces=faces, normals=normals)\n",
        "            mesh.export(\"nerf_reconstruction_fallback.stl\")\n",
        "            print(\"  --> Saved fallback mesh to nerf_reconstruction_fallback.stl\")\n",
        "            return mesh\n",
        "        except Exception as e2:\n",
        "            print(\"  Fallback also failed:\", e2)\n",
        "            return None\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 9. Chamfer Distance\n",
        "################################################################################\n",
        "def chamfer_distance(points1, points2):\n",
        "    tree1 = cKDTree(points1)\n",
        "    tree2 = cKDTree(points2)\n",
        "    d1, _ = tree1.query(points2)\n",
        "    d2, _ = tree2.query(points1)\n",
        "    return np.mean(d1**2) + np.mean(d2**2)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 10. Plot Meshes\n",
        "################################################################################\n",
        "def plot_meshes(\n",
        "    gt_vertices, gt_faces, pred_vertices, pred_faces, outpath=\"mesh_comparison.png\"\n",
        "):\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(111, projection=\"3d\")\n",
        "\n",
        "    gt_center = np.mean(gt_vertices, axis=0)\n",
        "    pred_center = np.mean(pred_vertices, axis=0)\n",
        "    gt_vertices_centered = gt_vertices - gt_center\n",
        "    pred_vertices_centered = pred_vertices - pred_center\n",
        "    gt_scale = np.max(np.linalg.norm(gt_vertices_centered, axis=1))\n",
        "    pred_scale = np.max(np.linalg.norm(pred_vertices_centered, axis=1))\n",
        "    scale = max(gt_scale, pred_scale)\n",
        "\n",
        "    gt_vn = gt_vertices_centered / scale\n",
        "    pr_vn = pred_vertices_centered / scale\n",
        "\n",
        "    if (len(gt_faces) > 0) and (len(pred_faces) > 0):\n",
        "        ax.plot_trisurf(\n",
        "            gt_vn[:, 0],\n",
        "            gt_vn[:, 1],\n",
        "            gt_vn[:, 2],\n",
        "            triangles=gt_faces,\n",
        "            color=\"blue\",\n",
        "            alpha=0.5,\n",
        "        )\n",
        "        ax.plot_trisurf(\n",
        "            pr_vn[:, 0],\n",
        "            pr_vn[:, 1],\n",
        "            pr_vn[:, 2],\n",
        "            triangles=pred_faces,\n",
        "            color=\"red\",\n",
        "            alpha=0.5,\n",
        "        )\n",
        "        ax.set_title(\"GT (Blue) vs. Prediction (Red)\")\n",
        "        ax.set_box_aspect([1, 1, 1])\n",
        "        plt.savefig(outpath)\n",
        "        plt.show()\n",
        "        print(f\"[PLOT] Saved mesh comparison to {outpath}\")\n",
        "    else:\n",
        "        print(\"[PLOT] Could not plot: empty faces.\")\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 11. Training Loop (with Additional Debug)\n",
        "################################################################################\n",
        "def train_nerf(\n",
        "    model,\n",
        "    rays_o_all,\n",
        "    rays_d_all,\n",
        "    target_pixels_all,\n",
        "    mask_all,\n",
        "    image_shape,\n",
        "    num_iterations=8000,\n",
        "    device=None,\n",
        "    near=0.5,\n",
        "    far=1.5,\n",
        "    sigma_scale=2.0,\n",
        "    debug_interval=1000,\n",
        "    out_dir=\"debug_renders\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Weighted sampling of rays => silhouette & edges get emphasis.\n",
        "    Combined loss from silhouette, spherical prior, density, smoothness.\n",
        "    Now also includes side-by-side mask vs alpha debug plots.\n",
        "    \"\"\"\n",
        "    H, W = image_shape\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
        "    \n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=500) # Korrigierte Zeile\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # Adjust these if you see alpha saturating or shape not forming\n",
        "    lambda_sil = 1.0\n",
        "    lambda_shape = 1e-3\n",
        "    lambda_density = 0.2\n",
        "    lambda_smooth = 0.1\n",
        "\n",
        "    best_loss = float(\"inf\")\n",
        "    print(\"[TRAIN] Starting training ...\")\n",
        "\n",
        "    for i in trange(num_iterations, desc=\"Training\", unit=\"iter\"):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        rays_o_batch, rays_d_batch, rgb_batch, mask_batch = sample_rays_weighted(\n",
        "            rays_o_all,\n",
        "            rays_d_all,\n",
        "            target_pixels_all,\n",
        "            mask_all,\n",
        "            original_shape=(H, W),\n",
        "            batch_size=1024,\n",
        "        )\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            rgb_map, alpha_map = render_rays(\n",
        "                model,\n",
        "                rays_o_batch,\n",
        "                rays_d_batch,\n",
        "                near=near,\n",
        "                far=far,\n",
        "                sigma_scale=sigma_scale,\n",
        "                N_samples=64,\n",
        "            )\n",
        "            photo_loss = torch.mean((rgb_map - rgb_batch) ** 2)\n",
        "            sil_loss_val = silhouette_loss(alpha_map, mask_batch)\n",
        "            shape_loss_val = spherical_prior_loss(\n",
        "                model,\n",
        "                bound=1.0,\n",
        "                desired_radius=0.6,\n",
        "                sigma_scale=sigma_scale,\n",
        "                device=device,\n",
        "            )\n",
        "            dens_loss_val = foreground_density_loss(\n",
        "                alpha_map, mask_batch, target_density=1.0\n",
        "            )\n",
        "            smooth_loss_val = smoothness_prior_loss(\n",
        "                model, bound=1.0, offset=0.01, sigma_scale=sigma_scale, device=device\n",
        "            )\n",
        "\n",
        "            total_loss = (\n",
        "                photo_loss\n",
        "                + lambda_sil * sil_loss_val\n",
        "                + lambda_shape * shape_loss_val\n",
        "                + lambda_density * dens_loss_val\n",
        "                + lambda_smooth * smooth_loss_val\n",
        "            )\n",
        "\n",
        "        scaler.scale(total_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step(total_loss)\n",
        "\n",
        "        if (i + 1) % 200 == 0:\n",
        "            print(\n",
        "                f\"Iter {i + 1}: total={total_loss.item():.4f}, \"\n",
        "                f\"photo={photo_loss.item():.4f}, sil={sil_loss_val.item():.4f}, \"\n",
        "                f\"shape={shape_loss_val.item():.4f}, dens={dens_loss_val.item():.4f}, \"\n",
        "                f\"smooth={smooth_loss_val.item():.4f}\"\n",
        "            )\n",
        "            # Save best model\n",
        "            if total_loss.item() < best_loss:\n",
        "                best_loss = total_loss.item()\n",
        "                torch.save(model.state_dict(), \"nerf_best_model.pth\")\n",
        "                print(\"[TRAIN] ==> New best model saved.\")\n",
        "\n",
        "        # Debug rendering every debug_interval\n",
        "        if (i + 1) % debug_interval == 0:\n",
        "            print(f\"[DEBUG] Rendering images at iteration {i + 1} ...\")\n",
        "\n",
        "            # 1) Render front\n",
        "            front_rays_o = rays_o_all[: H * W]\n",
        "            front_rays_d = rays_d_all[: H * W]\n",
        "            front_mask = mask_all[: H * W]  # ground-truth silhouette\n",
        "\n",
        "            debug_render(\n",
        "                model,\n",
        "                front_rays_o,\n",
        "                front_rays_d,\n",
        "                H,\n",
        "                W,\n",
        "                near=near,\n",
        "                far=far,\n",
        "                sigma_scale=sigma_scale,\n",
        "                device=device,\n",
        "                title_prefix=\"front\",\n",
        "                iteration=i + 1,\n",
        "                out_dir=out_dir,\n",
        "            )\n",
        "            debug_compare_mask_and_alpha(\n",
        "                model,\n",
        "                front_rays_o,\n",
        "                front_rays_d,\n",
        "                front_mask,\n",
        "                H,\n",
        "                W,\n",
        "                near=near,\n",
        "                far=far,\n",
        "                sigma_scale=sigma_scale,\n",
        "                device=device,\n",
        "                title_prefix=\"front\",\n",
        "                iteration=i + 1,\n",
        "                out_dir=out_dir,\n",
        "            )\n",
        "\n",
        "            # 2) Render side\n",
        "            side_rays_o = rays_o_all[H * W : 2 * H * W]\n",
        "            side_rays_d = rays_d_all[H * W : 2 * H * W]\n",
        "            side_mask = mask_all[H * W : 2 * H * W]\n",
        "\n",
        "            debug_render(\n",
        "                model,\n",
        "                side_rays_o,\n",
        "                side_rays_d,\n",
        "                H,\n",
        "                W,\n",
        "                near=near,\n",
        "                far=far,\n",
        "                sigma_scale=sigma_scale,\n",
        "                device=device,\n",
        "                title_prefix=\"side\",\n",
        "                iteration=i + 1,\n",
        "                out_dir=out_dir,\n",
        "            )\n",
        "            debug_compare_mask_and_alpha(\n",
        "                model,\n",
        "                side_rays_o,\n",
        "                side_rays_d,\n",
        "                side_mask,\n",
        "                H,\n",
        "                W,\n",
        "                near=near,\n",
        "                far=far,\n",
        "                sigma_scale=sigma_scale,\n",
        "                device=device,\n",
        "                title_prefix=\"side\",\n",
        "                iteration=i + 1,\n",
        "                out_dir=out_dir,\n",
        "            )\n",
        "\n",
        "            # Save checkpoint\n",
        "            ckpt_path = f\"nerf_checkpoint_{i + 1}.pth\"\n",
        "            torch.save(model.state_dict(), ckpt_path)\n",
        "            print(f\"[TRAIN] Saved checkpoint {ckpt_path}\\n\")\n",
        "\n",
        "    print(\"[TRAIN] Done.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 12. Main\n",
        "################################################################################\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load real PollenDataset\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"[SYS] Using device:\", device)\n",
        "\n",
        "    image_transform = transforms.ToTensor()\n",
        "    dataset, train_ids, test_ids = get_train_test_split(\n",
        "        image_transforms=image_transform,\n",
        "        mesh_transforms=None,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # 2) Select a sample\n",
        "    (left_img, right_img), gt_points, rotations, voxels = dataset[train_ids[0]]\n",
        "    print(\n",
        "        f\"[DATA] Loaded sample #{train_ids[0]} → \"\n",
        "        f\"images: {left_img.shape},{right_img.shape}; \"\n",
        "        f\"points: {gt_points.shape}; \"\n",
        "        f\"rotations (rad): {rotations.tolist()}; \"\n",
        "        f\"voxels: {voxels.shape if hasattr(voxels, 'shape') else voxels}\"\n",
        "    )\n",
        "\n",
        "    # 3) Ensure 3‐channel\n",
        "    if left_img.ndim == 2:\n",
        "        left_img = left_img.unsqueeze(0)\n",
        "    if right_img.ndim == 2:\n",
        "        right_img = right_img.unsqueeze(0)\n",
        "    if left_img.shape[0] == 1:\n",
        "        left_img = left_img.repeat(3, 1, 1)\n",
        "    if right_img.shape[0] == 1:\n",
        "        right_img = right_img.repeat(3, 1, 1)\n",
        "\n",
        "    # 4) Normalize to [0,1]\n",
        "    if left_img.max() > 1.0:\n",
        "        left_img /= 255.0\n",
        "    if right_img.max() > 1.0:\n",
        "        right_img /= 255.0\n",
        "\n",
        "    # 5) Show raw images\n",
        "    H, W = left_img.shape[1], left_img.shape[2]\n",
        "    print(f\"[DATA] Image dimensions: {H}x{W}\")\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(left_img.permute(1, 2, 0).cpu(), interpolation=\"nearest\")\n",
        "    plt.title(\"Left Image\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(right_img.permute(1, 2, 0).cpu(), interpolation=\"nearest\")\n",
        "    plt.title(\"Right Image\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # 6) Silhouettes as before…\n",
        "    left_gray = left_img.mean(dim=0, keepdim=True)\n",
        "    right_gray = right_img.mean(dim=0, keepdim=True)\n",
        "    left_gray = torch.nn.functional.avg_pool2d(\n",
        "        left_gray.unsqueeze(0), 5, stride=1, padding=2\n",
        "    ).squeeze()\n",
        "    right_gray = torch.nn.functional.avg_pool2d(\n",
        "        right_gray.unsqueeze(0), 5, stride=1, padding=2\n",
        "    ).squeeze()\n",
        "    left_mask = (left_gray > 0.2).float().reshape(-1)\n",
        "    right_mask = (right_gray > 0.2).float().reshape(-1)\n",
        "\n",
        "    # 7) Flatten colors\n",
        "    left_img_tensor = left_img.permute(1, 2, 0).reshape(-1, 3).float()\n",
        "    right_img_tensor = right_img.permute(1, 2, 0).reshape(-1, 3).float()\n",
        "\n",
        "    # 8) Generate canonical (unrotated) rays\n",
        "    focal = 300.0\n",
        "    rays_o_f, rays_d_f, rays_o_s, rays_d_s = get_rays(H, W, focal=focal)\n",
        "\n",
        "    # 9) Rotate both front & side rays by the sample's Euler angles\n",
        "    rays_o_front, rays_d_front = rotate_rays(rays_o_f, rays_d_f, rotations)\n",
        "    rays_o_side, rays_d_side = rotate_rays(rays_o_s, rays_d_s, rotations)\n",
        "\n",
        "    # 10) Concatenate both views\n",
        "    rays_o_all = torch.cat([rays_o_front, rays_o_side], dim=0).to(device)\n",
        "    rays_d_all = torch.cat([rays_d_front, rays_d_side], dim=0).to(device)\n",
        "    target_pixels_all = torch.cat([left_img_tensor, right_img_tensor], dim=0).to(device)\n",
        "    mask_all = torch.cat([left_mask, right_mask], dim=0).to(device)\n",
        "\n",
        "    # 11) Initialize NeRF & Train (unchanged)\n",
        "    model = NeRF(D=6, W=128, L=4).to(device)\n",
        "    model = train_nerf(\n",
        "        model,\n",
        "        rays_o_all,\n",
        "        rays_d_all,\n",
        "        target_pixels_all,\n",
        "        mask_all,\n",
        "        image_shape=(H, W),\n",
        "        num_iterations=10000,\n",
        "        device=device,\n",
        "        near=0.5,\n",
        "        far=1.5,\n",
        "        sigma_scale=1.0,\n",
        "        debug_interval=2000,\n",
        "        out_dir=\"debug_renders\",\n",
        "    )\n",
        "\n",
        "    # 12) Extract mesh & (optional) compare to gt_points…\n",
        "    pred_mesh = extract_3d_from_nerf(\n",
        "        model, resolution=256, bound=1.0, sigma_scale=1.0, device=device\n",
        "    )\n",
        "    if pred_mesh is not None:\n",
        "        pred_points = pred_mesh.sample(5000)\n",
        "        cd = chamfer_distance(pred_points, gt_points.cpu().numpy())\n",
        "        print(f\"\\n[RESULT] Chamfer Dist (Pred vs. GT point‐cloud): {cd:.6f}\")\n",
        "    print(\"\\nDone.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 Strong Shape Prior\n",
        "## 5.1 Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 8000/8000 [02:59<00:00, 44.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "from scipy.spatial import cKDTree\n",
        "from skimage.measure import marching_cubes\n",
        "import trimesh\n",
        "\n",
        "# If you have the data package\n",
        "sys.path.append(\"..\")\n",
        "try:\n",
        "    from data.pollen_dataset import PollenDataset, get_train_test_split\n",
        "except ImportError:\n",
        "    PollenDataset = None\n",
        "    get_train_test_split = None\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. Positional Encoding (Reduced Frequencies)\n",
        "# -----------------------------------------------------------------------------\n",
        "def positional_encoding(x, L=4):\n",
        "    out = [x]\n",
        "    for i in range(L):\n",
        "        for fn in (torch.sin, torch.cos):\n",
        "            out.append(fn((2.0**i) * np.pi * x))\n",
        "    return torch.cat(out, dim=-1)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 2. NeRF Model\n",
        "# -----------------------------------------------------------------------------\n",
        "class NeRF(nn.Module):\n",
        "    def __init__(self, D=6, W=128, L=4):\n",
        "        super(NeRF, self).__init__()\n",
        "        self.L = L\n",
        "        in_ch = 3 * (2 * L + 1)\n",
        "        layers = [nn.Linear(in_ch, W)] + [nn.Linear(W, W) for _ in range(D - 1)]\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.output_layer = nn.Linear(W, 4)\n",
        "        with torch.no_grad():\n",
        "            self.output_layer.bias[3] = 0.1\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_enc = positional_encoding(x, self.L)\n",
        "        h = x_enc\n",
        "        for l in self.layers:\n",
        "            h = torch.relu(l(h))\n",
        "        return self.output_layer(h)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 3. Render Rays\n",
        "# -----------------------------------------------------------------------------\n",
        "def render_rays(\n",
        "    model, rays_o, rays_d, near=0.5, far=1.5, N_samples=128, sigma_scale=1.0\n",
        "):\n",
        "    device = rays_o.device\n",
        "    z_vals = torch.linspace(near, far, N_samples, device=device)\n",
        "    pts = rays_o[:, None, :] + rays_d[:, None, :] * z_vals[None, :, None]\n",
        "    raw = model(pts.reshape(-1, 3)).reshape(pts.shape[0], N_samples, 4)\n",
        "    rgb = torch.sigmoid(raw[..., :3])\n",
        "    sigma = torch.relu(raw[..., 3]) * sigma_scale\n",
        "    deltas = torch.cat([z_vals[1:] - z_vals[:-1], torch.tensor([1e10], device=device)])\n",
        "    deltas = deltas[None, :].expand(sigma.shape)\n",
        "    alpha = 1.0 - torch.exp(-sigma * deltas)\n",
        "    T = torch.cumprod(\n",
        "        torch.cat(\n",
        "            [torch.ones((sigma.shape[0], 1), device=device), 1 - alpha + 1e-10], dim=-1\n",
        "        ),\n",
        "        dim=-1,\n",
        "    )[:, :-1]\n",
        "    weights = alpha * T\n",
        "    rgb_map = torch.sum(weights[..., None] * rgb, dim=1)\n",
        "    alpha_map = torch.sum(weights, dim=1)\n",
        "    return rgb_map, alpha_map\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 4. Losses\n",
        "# -----------------------------------------------------------------------------\n",
        "def silhouette_loss(alpha, mask):\n",
        "    return torch.mean((alpha - mask) ** 2)\n",
        "\n",
        "\n",
        "def spherical_prior_loss(\n",
        "    model, num_samples=2000, bound=1.0, desired_radius=0.6, sigma_scale=2.0, device=None\n",
        "):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    coords = torch.rand(num_samples, 3, device=device) * (2 * bound) - bound\n",
        "    sigma = torch.relu(model(coords)[..., 3]) * sigma_scale\n",
        "    d = torch.norm(coords, dim=1)\n",
        "    return torch.mean(sigma * (d - desired_radius) ** 2)\n",
        "\n",
        "\n",
        "def foreground_density_loss(alpha, mask, target_density=1.0):\n",
        "    D = -torch.log(1 - alpha + 1e-6)\n",
        "    fg = mask > 0.5\n",
        "    if fg.sum() > 0:\n",
        "        return torch.mean(torch.clamp(target_density - D[fg], min=0.0))\n",
        "    return torch.tensor(0.0, device=alpha.device)\n",
        "\n",
        "\n",
        "def smoothness_prior_loss(\n",
        "    model, num_samples=2000, bound=1.0, offset=0.01, sigma_scale=2.0, device=None\n",
        "):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    coords = torch.rand(num_samples, 3, device=device) * (2 * bound) - bound\n",
        "    sigma0 = torch.relu(model(coords)[..., 3]) * sigma_scale\n",
        "    offsets = torch.tensor(\n",
        "        [\n",
        "            [offset, 0, 0],\n",
        "            [-offset, 0, 0],\n",
        "            [0, offset, 0],\n",
        "            [0, -offset, 0],\n",
        "            [0, 0, offset],\n",
        "            [0, 0, -offset],\n",
        "        ],\n",
        "        device=device,\n",
        "    )\n",
        "    diffs = []\n",
        "    for off in offsets:\n",
        "        sigma1 = torch.relu(model(coords + off)[..., 3]) * sigma_scale\n",
        "        diffs.append(torch.mean((sigma0 - sigma1) ** 2))\n",
        "    return sum(diffs) / len(diffs)\n",
        "\n",
        "\n",
        "# New strong priors:\n",
        "def radial_profile_loss(\n",
        "    model,\n",
        "    num_samples=5000,\n",
        "    bound=1.0,\n",
        "    desired_radius=0.6,\n",
        "    sigma_scale=2.0,\n",
        "    width=0.05,\n",
        "    device=None,\n",
        "):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    coords = (torch.rand(num_samples, 3, device=device) * 2 - 1) * bound\n",
        "    sigma = torch.relu(model(coords)[..., 3]) * sigma_scale\n",
        "    d = torch.norm(coords, dim=1)\n",
        "    target = torch.exp(-0.5 * ((d - desired_radius) / width) ** 2)\n",
        "    return torch.mean((sigma - target) ** 2)\n",
        "\n",
        "\n",
        "def symmetry_loss(model, num_samples=5000, bound=1.0, sigma_scale=2.0, device=None):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    coords = (torch.rand(num_samples, 3, device=device) * 2 - 1) * bound\n",
        "    sigma0 = torch.relu(model(coords)[..., 3]) * sigma_scale\n",
        "    losses = []\n",
        "    for axis in range(3):\n",
        "        refl = coords.clone()\n",
        "        refl[:, axis] *= -1\n",
        "        sigma1 = torch.relu(model(refl)[..., 3]) * sigma_scale\n",
        "        losses.append(torch.mean((sigma0 - sigma1) ** 2))\n",
        "    return sum(losses) / len(losses)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 5. Rays & Rotation\n",
        "# -----------------------------------------------------------------------------\n",
        "import torch\n",
        "from trimesh.transformations import euler_matrix\n",
        "\n",
        "\n",
        "def get_rays(H, W, focal=300.0):\n",
        "    i, j = torch.meshgrid(\n",
        "        torch.linspace(0, W - 1, W), torch.linspace(0, H - 1, H), indexing=\"xy\"\n",
        "    )\n",
        "    dirs = torch.stack(\n",
        "        [(i - W / 2) / focal, -(j - H / 2) / focal, -torch.ones_like(i)], dim=-1\n",
        "    )\n",
        "    d = dirs / torch.norm(dirs, dim=-1, keepdim=True)\n",
        "    o = torch.zeros_like(d)\n",
        "    return o.reshape(-1, 3), d.reshape(-1, 3)\n",
        "\n",
        "\n",
        "def rotate_rays(o, d, angles):\n",
        "    R4 = euler_matrix(float(angles[0]), float(angles[1]), float(angles[2]), \"sxyz\")\n",
        "    R = torch.from_numpy(R4[:3, :3]).float().to(o.device)\n",
        "    return (R @ o.T).T, (R @ d.T).T\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 6. Weighted Sampling\n",
        "# -----------------------------------------------------------------------------\n",
        "def sample_rays_weighted(rays_o, rays_d, rgb, mask, original_shape, batch_size=1024):\n",
        "    H, W = original_shape\n",
        "    ppv = H * W\n",
        "    weights = []\n",
        "    # two views\n",
        "    for v in range(2):\n",
        "        m = mask[v * ppv : (v + 1) * ppv].reshape(H, W)\n",
        "        k = (\n",
        "            torch.tensor(\n",
        "                [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], device=m.device\n",
        "            ).float()\n",
        "            / 8\n",
        "        )\n",
        "        edges = torch.abs(\n",
        "            torch.nn.functional.conv2d(\n",
        "                m.unsqueeze(0).unsqueeze(0), k.unsqueeze(0).unsqueeze(0), padding=1\n",
        "            )\n",
        "        ).reshape(H, W)\n",
        "        w = (\n",
        "            edges.reshape(-1)\n",
        "            + 0.1\n",
        "            + (mask[v * ppv : (v + 1) * ppv] > 0.5).float() * 2.0\n",
        "        )\n",
        "        weights.append(w)\n",
        "    p = torch.cat(weights)\n",
        "    p /= p.sum()\n",
        "    idx = torch.multinomial(p, batch_size, replacement=True)\n",
        "    return rays_o[idx], rays_d[idx], rgb[idx], mask[idx]\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 7. Debug & 8. Marching Cubes, 9. Chamfer same as before\n",
        "# ... (omitted for brevity; copy your existing debug_render, debug_compare, extract_3d_from_nerf, chamfer_distance)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 10. Training\n",
        "# -----------------------------------------------------------------------------\n",
        "def train_nerf(\n",
        "    model,\n",
        "    rays_o_all,\n",
        "    rays_d_all,\n",
        "    target_pixels_all,\n",
        "    mask_all,\n",
        "    image_shape,\n",
        "    num_iterations=8000,\n",
        "    device=None,\n",
        "    near=0.5,\n",
        "    far=1.5,\n",
        "    sigma_scale=2.0,\n",
        "    debug_interval=1000,\n",
        "    out_dir=\"debug_renders\",\n",
        "):\n",
        "    H, W = image_shape\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    opt = optim.Adam(model.parameters(), lr=5e-4)\n",
        "    sch = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        opt, mode=\"min\", factor=0.5, patience=300\n",
        "    )\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # strong prior lambdas\n",
        "    lambda_sil = 4.0\n",
        "    lambda_shape = 3.0\n",
        "    lambda_density = 0.5\n",
        "    lambda_smooth = 0.5\n",
        "    lambda_radial = 3.0\n",
        "    lambda_sym = 5.0\n",
        "\n",
        "    best = 1e9\n",
        "    for i in trange(num_iterations, desc=\"Training\"):\n",
        "        opt.zero_grad()\n",
        "        ro, rd, rgbB, mB = sample_rays_weighted(\n",
        "            rays_o_all, rays_d_all, target_pixels_all, mask_all, (H, W), 1024\n",
        "        )\n",
        "        with torch.cuda.amp.autocast():\n",
        "            rgb_map, alpha_map = render_rays(model, ro, rd, near, far, 64, sigma_scale)\n",
        "            Lp = torch.mean((rgb_map - rgbB) ** 2)\n",
        "            Ls = silhouette_loss(alpha_map, mB)\n",
        "            Lh = spherical_prior_loss(model, device=device)\n",
        "            Ld = foreground_density_loss(alpha_map, mB)\n",
        "            Lsm = smoothness_prior_loss(model, device=device)\n",
        "            Lr = radial_profile_loss(model, device=device)\n",
        "            Lsy = symmetry_loss(model, device=device)\n",
        "            loss = (\n",
        "                Lp\n",
        "                + lambda_sil * Ls\n",
        "                + lambda_shape * Lh\n",
        "                + lambda_density * Ld\n",
        "                + lambda_smooth * Lsm\n",
        "                + lambda_radial * Lr\n",
        "                + lambda_sym * Lsy\n",
        "            )\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "        sch.step(loss)\n",
        "        if (i + 1) % 200 == 0 and loss < best:\n",
        "            best = loss\n",
        "            torch.save(model.state_dict(), \"nerf_best.pth\")\n",
        "        if (i + 1) % debug_interval == 0:\n",
        "            # debug_render calls...\n",
        "            pass\n",
        "    return model\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 11. Main\n",
        "# -----------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", dev)\n",
        "    tf = transforms.ToTensor()\n",
        "    dataset, train_ids, _ = get_train_test_split(image_transforms=tf, device=dev)\n",
        "    (l_img, r_img), pts, rot, vox = dataset[train_ids[0]]\n",
        "    # prepare two views as before\n",
        "    H, W = l_img.shape[1:]\n",
        "    o_f, d_f = get_rays(H, W, 300.0)\n",
        "    o1, d1 = rotate_rays(o_f, d_f, rot)\n",
        "    o2, d2 = rotate_rays(o_f, d_f, rot)\n",
        "    # flatten images,masks, then cat\n",
        "    # ... (same as your code)\n",
        "    rays_o_all = torch.cat([o1, o2], dim=0).to(dev)\n",
        "    rays_d_all = torch.cat([d1, d2], dim=0).to(dev)\n",
        "    # target_pixels_all, mask_all built similarly\n",
        "    model = NeRF().to(dev)\n",
        "    model = train_nerf(\n",
        "        model, rays_o_all, rays_d_all, target_pixels_all, mask_all, (H, W), device=dev\n",
        "    )\n",
        "    # extract mesh & chamfer\n",
        "\n",
        "    print(\"Done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:[SYS] Verwende Gerät: cuda\n",
            "WARNING:__main__:************************************************************\n",
            "WARNING:__main__:!!! ACHTUNG: VERWENDUNG VON STARKEN ANNAHMEN STATT METADATEN !!!\n",
            "WARNING:__main__:!!! Annahmen: Dist=1.5, Scale=0.8, Near=0.50, Far=2.50 !!!\n",
            "WARNING:__main__:!!! Ergebnisse sind wahrscheinlich geometrisch ungenau!       !!!\n",
            "WARNING:__main__:************************************************************\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:[DATA] Lade Sample #86 (sample_86)\n",
            "INFO:__main__:  Bilder: torch.Size([1, 1024, 1024]), torch.Size([1, 1024, 1024])\n",
            "INFO:__main__:  GT Punkte: torch.Size([4000, 3])\n",
            "INFO:__main__:  Objekt Rotation (rad): [42.67660903930664, 57.744712829589844, 296.34222412109375]\n",
            "INFO:__main__:[DATA] Bild Dimensionen: H=1024, W=1024\n",
            "INFO:__main__:Generiere KANONISCHE Strahlen basierend auf festen Annahmen...\n",
            "WARNING:__main__:!!! Verwendung von get_rays_fixed_assumptions !!!\n",
            "WARNING:__main__:!!! Ergebnisse sind wahrscheinlich ungenau, da Metadaten ignoriert werden !!!\n",
            "INFO:__main__:Rotiere kanonische Strahlen mit INVERSER Objekt-Rotation...\n",
            "INFO:__main__:Gesamtzahl Strahlen für Training: 2097152\n",
            "INFO:__main__:[TRAIN] Starte Training für 10000 Iterationen.\n",
            "INFO:__main__:[TRAIN] Views=2, H=1024, W=1024, Total rays=2097152\n",
            "INFO:__main__:[TRAIN] Near=0.5000, Far=2.5000\n",
            "INFO:__main__:[TRAIN] Loss Lambdas: Photo=1.0, Sil=1.0, Shape=0.0001, Dens=0.05, Smooth=0.0001\n",
            "Iter 2000/10000 | Loss: 0.0388 LR: 2.5e-04:  20%|█▉        | 1997/10000 [00:44<02:56, 45.28iter/s]INFO:__main__:\n",
            "[DEBUG] Rendere Debug-Ansichten bei Iteration 2000...\n",
            "INFO:__main__:[view0 DEBUG RENDER] Saved debug images at iter 2000 in debug_sample_86_ASSUMED/\n",
            "Iter 2000/10000 | Loss: 0.0388 LR: 2.5e-04:  20%|█▉        | 1997/10000 [00:57<02:56, 45.28iter/s]INFO:__main__:[view0 DEBUG MASK] Saved mask comparison at iter 2000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view1 DEBUG RENDER] Saved debug images at iter 2000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view1 DEBUG MASK] Saved mask comparison at iter 2000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[TRAIN] Checkpoint nerf_checkpoint_2000.pth gespeichert\n",
            "INFO:__main__:[DEBUG] Debug-Rendering beendet.\n",
            "Iter 4000/10000 | Loss: 0.0258 LR: 2.5e-04:  40%|███▉      | 3995/10000 [01:58<02:14, 44.61iter/s]  INFO:__main__:\n",
            "[DEBUG] Rendere Debug-Ansichten bei Iteration 4000...\n",
            "INFO:__main__:[view0 DEBUG RENDER] Saved debug images at iter 4000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view0 DEBUG MASK] Saved mask comparison at iter 4000 in debug_sample_86_ASSUMED/\n",
            "Iter 4000/10000 | Loss: 0.0258 LR: 2.5e-04:  40%|███▉      | 3995/10000 [02:17<02:14, 44.61iter/s]INFO:__main__:[view1 DEBUG RENDER] Saved debug images at iter 4000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view1 DEBUG MASK] Saved mask comparison at iter 4000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[TRAIN] Checkpoint nerf_checkpoint_4000.pth gespeichert\n",
            "INFO:__main__:[DEBUG] Debug-Rendering beendet.\n",
            "Iter 6000/10000 | Loss: 0.0227 LR: 3.1e-05:  60%|█████▉    | 5998/10000 [03:13<01:45, 37.97iter/s]  INFO:__main__:\n",
            "[DEBUG] Rendere Debug-Ansichten bei Iteration 6000...\n",
            "INFO:__main__:[view0 DEBUG RENDER] Saved debug images at iter 6000 in debug_sample_86_ASSUMED/\n",
            "Iter 6000/10000 | Loss: 0.0227 LR: 3.1e-05:  60%|█████▉    | 5998/10000 [03:27<01:45, 37.97iter/s]INFO:__main__:[view0 DEBUG MASK] Saved mask comparison at iter 6000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view1 DEBUG RENDER] Saved debug images at iter 6000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view1 DEBUG MASK] Saved mask comparison at iter 6000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[TRAIN] Checkpoint nerf_checkpoint_6000.pth gespeichert\n",
            "INFO:__main__:[DEBUG] Debug-Rendering beendet.\n",
            "Iter 8000/10000 | Loss: 0.0190 LR: 2.0e-06:  80%|███████▉  | 7996/10000 [04:34<00:48, 41.21iter/s]  INFO:__main__:\n",
            "[DEBUG] Rendere Debug-Ansichten bei Iteration 8000...\n",
            "INFO:__main__:[view0 DEBUG RENDER] Saved debug images at iter 8000 in debug_sample_86_ASSUMED/\n",
            "Iter 8000/10000 | Loss: 0.0190 LR: 2.0e-06:  80%|███████▉  | 7996/10000 [04:47<00:48, 41.21iter/s]INFO:__main__:[view0 DEBUG MASK] Saved mask comparison at iter 8000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view1 DEBUG RENDER] Saved debug images at iter 8000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view1 DEBUG MASK] Saved mask comparison at iter 8000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[TRAIN] Checkpoint nerf_checkpoint_8000.pth gespeichert\n",
            "INFO:__main__:[DEBUG] Debug-Rendering beendet.\n",
            "Iter 10000/10000 | Loss: 0.0178 LR: 2.4e-07: 100%|█████████▉| 9998/10000 [05:55<00:00, 39.95iter/s] INFO:__main__:\n",
            "[DEBUG] Rendere Debug-Ansichten bei Iteration 10000...\n",
            "INFO:__main__:[view0 DEBUG RENDER] Saved debug images at iter 10000 in debug_sample_86_ASSUMED/\n",
            "Iter 10000/10000 | Loss: 0.0178 LR: 2.4e-07: 100%|█████████▉| 9998/10000 [06:07<00:00, 39.95iter/s]INFO:__main__:[view0 DEBUG MASK] Saved mask comparison at iter 10000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view1 DEBUG RENDER] Saved debug images at iter 10000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[view1 DEBUG MASK] Saved mask comparison at iter 10000 in debug_sample_86_ASSUMED/\n",
            "INFO:__main__:[TRAIN] Checkpoint nerf_checkpoint_10000.pth gespeichert\n",
            "INFO:__main__:[DEBUG] Debug-Rendering beendet.\n",
            "Iter 10000/10000 | Loss: 0.0178 LR: 2.4e-07: 100%|██████████| 10000/10000 [06:24<00:00, 26.02iter/s]\n",
            "INFO:__main__:[TRAIN] Training beendet.\n",
            "INFO:__main__:Lade besten Modellzustand.\n",
            "INFO:__main__:\n",
            "[EXTRACT 3D] Führe Marching Cubes aus (Res=192, Bound=1.0, Thresh=10.0)...\n",
            "INFO:__main__:  Sigma Volumen Stats: min=0.0000, max=23.0612, mean=0.4665, std=1.6958\n",
            "INFO:__main__:  Verwende Iso-Level (Threshold) = 10.0000\n",
            "INFO:__main__:  --> Mesh gespeichert (28022V, 55260F) nach ./sample_86_reconstruction_ASSUMED.stl\n",
            "INFO:__main__:\n",
            "[RESULT] Chamfer Distanz (vs GT Punkte): 1706.784227\n",
            "INFO:__main__:\n",
            "Verarbeitung für Sample sample_86 (mit Annahmen) beendet.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "\n",
        "# Imports für optionale Features (ggf. nachinstallieren: pip install scipy scikit-image trimesh)\n",
        "try:\n",
        "    from scipy.spatial import cKDTree\n",
        "    from skimage.measure import marching_cubes\n",
        "    import trimesh\n",
        "    from trimesh.transformations import euler_matrix, inverse_matrix # Hinzugefügt: inverse_matrix\n",
        "except ImportError:\n",
        "    logging.warning(\"Optionale Pakete (scipy, scikit-image, trimesh) nicht gefunden. Einige Features sind nicht verfügbar.\")\n",
        "    cKDTree = None\n",
        "    marching_cubes = None\n",
        "    trimesh = None\n",
        "    # Fallback für Transformationsfunktionen, falls trimesh fehlt (nicht empfohlen)\n",
        "    def euler_matrix(ai, aj, ak, axes): return np.eye(4)\n",
        "    def inverse_matrix(m): return np.linalg.inv(m)\n",
        "\n",
        "\n",
        "# Wenn das Datenpaket vorhanden ist\n",
        "# sys.path.append(\"..\") # Auskommentiert, wenn nicht benötigt\n",
        "try:\n",
        "    from data.pollen_dataset import PollenDataset, get_train_test_split\n",
        "except ImportError:\n",
        "    # Fallback, falls nicht verfügbar\n",
        "    PollenDataset = None\n",
        "    get_train_test_split = None\n",
        "\n",
        "# Performance-Optimierung\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 1. Positional Encoding (Unverändert)\n",
        "################################################################################\n",
        "def positional_encoding(x, L=4):\n",
        "    out = [x]\n",
        "    # torch.pi für Präzision verwenden\n",
        "    for i in range(L):\n",
        "        for fn in (torch.sin, torch.cos):\n",
        "            out.append(fn((2.0**i) * torch.pi * x))\n",
        "    return torch.cat(out, dim=-1)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 2. NeRF Model (Unverändert)\n",
        "################################################################################\n",
        "class NeRF(nn.Module):\n",
        "    def __init__(self, D=6, W=128, L=4):\n",
        "        super(NeRF, self).__init__()\n",
        "        self.L = L\n",
        "        # Korrekte Berechnung der Eingabekanäle\n",
        "        in_channels = 3 * (1 + 2 * L)\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(in_channels, W))\n",
        "        layers.append(nn.ReLU()) # Aktivierung hinzufügen\n",
        "        for _ in range(D - 1):\n",
        "            layers.append(nn.Linear(W, W))\n",
        "            layers.append(nn.ReLU()) # Aktivierung hinzufügen\n",
        "        self.mlp_layers = nn.Sequential(*layers)\n",
        "        self.output_layer = nn.Linear(W, 4)\n",
        "        with torch.no_grad():\n",
        "            self.output_layer.bias[3].fill_(0.1) # Initiale Dichte fördern\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_enc = positional_encoding(x, self.L)\n",
        "        h = self.mlp_layers(x_enc)\n",
        "        return self.output_layer(h)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 3. Render Rays (RGB + Alpha) (Unverändert)\n",
        "################################################################################\n",
        "def render_rays(\n",
        "    model, rays_o, rays_d, near=0.5, far=1.5, N_samples=128, sigma_scale=1.0, white_bkgd=False\n",
        "):\n",
        "    device = rays_o.device\n",
        "    z_vals = torch.linspace(near, far, N_samples, device=device)\n",
        "    pts = rays_o[:, None, :] + rays_d[:, None, :] * z_vals[None, :, None]\n",
        "    pts_flat = pts.reshape(-1, 3)\n",
        "    raw = model(pts_flat).reshape(pts.shape[0], N_samples, 4)\n",
        "    rgb = torch.sigmoid(raw[..., :3])\n",
        "    sigma = torch.relu(raw[..., 3]) * sigma_scale\n",
        "    deltas = z_vals[1:] - z_vals[:-1]\n",
        "    delta_inf = torch.tensor([1e10], device=device).expand(rays_o.shape[0])\n",
        "    deltas = torch.cat([deltas.expand(rays_o.shape[0], -1), delta_inf[:, None]], dim=-1)\n",
        "    alpha = 1.0 - torch.exp(-sigma * deltas)\n",
        "    T = torch.cumprod(\n",
        "        torch.cat(\n",
        "            [torch.ones((alpha.shape[0], 1), device=device), 1.0 - alpha + 1e-10],\n",
        "            dim=-1,\n",
        "        ),\n",
        "        dim=-1,\n",
        "    )[:, :-1]\n",
        "    weights = alpha * T\n",
        "    rgb_map = torch.sum(weights[..., None] * rgb, dim=1)\n",
        "    alpha_map = torch.sum(weights, dim=1)\n",
        "    if white_bkgd:\n",
        "        rgb_map = rgb_map + (1.0 - alpha_map[..., None])\n",
        "    return rgb_map, alpha_map\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 4. Losses: Silhouette, Priors (Unverändert)\n",
        "################################################################################\n",
        "def silhouette_loss(alpha_map, mask):\n",
        "    return torch.mean((alpha_map - mask.float()) ** 2)\n",
        "\n",
        "def spherical_prior_loss(\n",
        "    model, num_samples=2000, bound=1.0, desired_radius=0.6, sigma_scale=1.0, device=None\n",
        "):\n",
        "    if device is None: device = next(model.parameters()).device\n",
        "    coords = torch.rand(num_samples, 3, device=device) * (2 * bound) - bound\n",
        "    raw = model(coords)\n",
        "    sigma = torch.relu(raw[..., 3]) * sigma_scale\n",
        "    dists = torch.norm(coords, dim=1)\n",
        "    loss = torch.mean(sigma * (dists - desired_radius) ** 2)\n",
        "    return loss\n",
        "\n",
        "def foreground_density_loss(alpha_map, mask, target_density=1.0):\n",
        "    eps = 1e-6\n",
        "    fg_mask = mask > 0.5\n",
        "    if torch.sum(fg_mask) > 0:\n",
        "        # Penalize low alpha within the mask\n",
        "        return torch.mean(torch.clamp(target_density - alpha_map[fg_mask], min=0.0)**2)\n",
        "    else:\n",
        "        return torch.tensor(0.0, device=alpha_map.device)\n",
        "\n",
        "def smoothness_prior_loss(\n",
        "    model, num_samples=2000, bound=1.0, offset=0.01, sigma_scale=1.0, device=None\n",
        "):\n",
        "    if device is None: device = next(model.parameters()).device\n",
        "    coords = torch.rand(num_samples, 3, device=device) * (2 * bound) - bound\n",
        "    raw_center = model(coords)\n",
        "    sigma_center = torch.relu(raw_center[..., 3]) * sigma_scale\n",
        "    offsets = torch.tensor([\n",
        "        [offset,0,0],[-offset,0,0],[0,offset,0],[0,-offset,0],[0,0,offset],[0,0,-offset]\n",
        "    ], device=device).float()\n",
        "    total_diff = 0.0\n",
        "    for off in offsets:\n",
        "        raw_neighbor = model(coords + off)\n",
        "        sigma_neighbor = torch.relu(raw_neighbor[..., 3]) * sigma_scale\n",
        "        total_diff += torch.mean((sigma_center - sigma_neighbor) ** 2)\n",
        "    return total_diff / offsets.shape[0]\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 5. Ray Generation (Implementierung der STARKEN ANNAHMEN)\n",
        "################################################################################\n",
        "\n",
        "# ---------- HINZUGEFÜGT: Funktion zur Parallelstrahl-Generierung ----------\n",
        "# Diese Funktion wird benötigt, auch wenn wir feste Annahmen treffen,\n",
        "# um die Strahlen für die angenommenen parallelen Kameras zu berechnen.\n",
        "def get_parallel_rays(H, W, c2w, parallel_scale, near_clip, device='cpu'):\n",
        "    \"\"\"Generiert Strahlen für eine Parallelprojektionskamera.\"\"\"\n",
        "    if H <= 0 or W <= 0: raise ValueError(f\"Ungültige Bilddimensionen: H={H}, W={W}\")\n",
        "    c2w = c2w.to(device)\n",
        "    i, j = torch.meshgrid(torch.linspace(0,W-1,W,device=device), torch.linspace(0,H-1,H,device=device), indexing='xy')\n",
        "    i, j = i.reshape(-1), j.reshape(-1)\n",
        "    cam_right, cam_up, cam_fwd = c2w[:3,0], c2w[:3,1], c2w[:3,2]\n",
        "    view_dir = -cam_fwd\n",
        "    view_dir = view_dir / torch.linalg.norm(view_dir)\n",
        "    world_height = parallel_scale * 2.0\n",
        "    aspect_ratio = W / float(H) if H > 0 else 1.0\n",
        "    world_width = world_height * aspect_ratio\n",
        "    ndc_x = (i / (W-1)) * 2.0 - 1.0 if W > 1 else torch.zeros_like(i)\n",
        "    ndc_y = (j / (H-1)) * 2.0 - 1.0 if H > 1 else torch.zeros_like(j)\n",
        "    ndc_y = -ndc_y\n",
        "    cam_origin = c2w[:3,3]\n",
        "    plane_center = cam_origin + view_dir * near_clip\n",
        "    x_offset = cam_right.unsqueeze(0) * (ndc_x * world_width / 2.0).unsqueeze(1)\n",
        "    y_offset = cam_up.unsqueeze(0) * (ndc_y * world_height / 2.0).unsqueeze(1)\n",
        "    rays_o = plane_center.unsqueeze(0) + x_offset + y_offset\n",
        "    rays_d = view_dir.unsqueeze(0).expand_as(rays_o)\n",
        "    return rays_o.reshape(-1, 3), rays_d.reshape(-1, 3)\n",
        "# ---------- ENDE: Funktion zur Parallelstrahl-Generierung ----------\n",
        "\n",
        "\n",
        "# ---------- NEU: Funktion zur Generierung basierend auf Annahmen ----------\n",
        "def get_rays_fixed_assumptions(H, W, device='cpu'):\n",
        "    \"\"\"\n",
        "    Generiert kanonische (Objekt unrotiert) Strahlen für Front/Seite\n",
        "    basierend auf STARKEN ANNAHMEN über Kameraposition/-parameter.\n",
        "    VERWENDET NICHT DIE METADATEN! NICHT EMPFOHLEN!\n",
        "    \"\"\"\n",
        "    logger.warning(\"!!! Verwendung von get_rays_fixed_assumptions !!!\")\n",
        "    logger.warning(\"!!! Ergebnisse sind wahrscheinlich ungenau, da Metadaten ignoriert werden !!!\")\n",
        "\n",
        "    # --- STARKE ANNAHMEN (Werte hier ggf. anpassen) ---\n",
        "    ASSUMED_DISTANCE = 1.5  # Angenommener Abstand der Kameras zum Ursprung (0,0,0)\n",
        "    ASSUMED_PARALLEL_SCALE = 0.8 # Angenommener Skalierungsfaktor für Parallelprojektion\n",
        "    ASSUMED_SCENE_BOUND = 1.0 # Annahme: Objekt passt in [-1, 1] Würfel\n",
        "    # Nahe Ebene relativ zum Abstand, damit Objekt sichtbar ist\n",
        "    ASSUMED_NEAR_CLIP = ASSUMED_DISTANCE - ASSUMED_SCENE_BOUND * 1.1\n",
        "\n",
        "    # --- Feste Kameraposen (c2w) basierend auf Annahmen ---\n",
        "    # Kamera 1 (Front): Auf +Z-Achse, schaut auf Ursprung (-Z), Y ist oben\n",
        "    c2w_front_np = np.array([\n",
        "        [1, 0, 0, 0],\n",
        "        [0, 1, 0, 0],\n",
        "        [0, 0, 1, ASSUMED_DISTANCE],\n",
        "        [0, 0, 0, 1]\n",
        "    ], dtype=np.float32)\n",
        "    # Korrektur der Orientierung, damit sie -Z schaut (Standard NeRF/OpenGL Blickrichtung)\n",
        "    # Rotation um X-Achse um 180 Grad nötig, wenn Kamera standardmäßig -Z schaut\n",
        "    # Einfacher: Position setzen, LookAt verwenden (hier manuell gebaut)\n",
        "    # Richtungsvektoren (Rechts, Oben, Vorwärts) für c2w\n",
        "    # Vorwärts (cam_fwd = -view_dir): (0, 0, 1) -> schaut nach -Z\n",
        "    # Rechts (cam_right): (1, 0, 0)\n",
        "    # Oben (cam_up): (0, 1, 0)\n",
        "    c2w_front_np = np.array([\n",
        "        [1, 0, 0, 0],                     # Rechts = +X\n",
        "        [0, 1, 0, 0],                     # Oben = +Y\n",
        "        [0, 0, 1, ASSUMED_DISTANCE],      # Vorwärts = +Z (Position auf Z-Achse)\n",
        "        [0, 0, 0, 1]\n",
        "    ], dtype=np.float32)\n",
        "    c2w_front = torch.from_numpy(c2w_front_np).float()\n",
        "\n",
        "\n",
        "    # Kamera 2 (Seite): Auf +X-Achse, schaut auf Ursprung (-X), Y ist oben\n",
        "    # Vorwärts (cam_fwd = -view_dir): (1, 0, 0) -> schaut nach -X\n",
        "    # Rechts (cam_right): (0, 0, -1) # Kreuzprodukt view x up = (-1,0,0)x(0,1,0)=(0,0,-1)\n",
        "    # Oben (cam_up): (0, 1, 0)\n",
        "    c2w_side_np = np.array([\n",
        "        [0, 0, -1, ASSUMED_DISTANCE],      # Rechts = -Z (Position auf X-Achse)\n",
        "        [0, 1,  0, 0],                     # Oben = +Y\n",
        "        [1, 0,  0, 0],                     # Vorwärts = +X\n",
        "        [0, 0,  0, 1]\n",
        "    ], dtype=np.float32)\n",
        "    c2w_side = torch.from_numpy(c2w_side_np).float()\n",
        "\n",
        "    # --- Generiere KANONISCHE Parallelstrahlen für die ANGENOMMENEN Posen ---\n",
        "    # Objekt ist hier noch unrotiert\n",
        "    rays_o_f_can, rays_d_f_can = get_parallel_rays(\n",
        "        H, W, c2w_front, ASSUMED_PARALLEL_SCALE, ASSUMED_NEAR_CLIP, device=device\n",
        "    )\n",
        "    rays_o_s_can, rays_d_s_can = get_parallel_rays(\n",
        "        H, W, c2w_side, ASSUMED_PARALLEL_SCALE, ASSUMED_NEAR_CLIP, device=device\n",
        "    )\n",
        "\n",
        "    # Rückgabe der KANONISCHEN Strahlen (Rotation erfolgt später)\n",
        "    return rays_o_f_can, rays_d_f_can, rays_o_s_can, rays_d_s_can\n",
        "\n",
        "# ---------- ENDE: Funktion zur Generierung basierend auf Annahmen ----------\n",
        "\n",
        "\n",
        "# ---------- MODIFIZIERT: Rotiert Strahlen mit INVERSER Objekt-Rotation ----------\n",
        "def rotate_rays_inverse_object(rays_o, rays_d, object_euler_angles):\n",
        "    \"\"\"\n",
        "    Rotiert die KANONISCHEN Kamera-Strahlen mit der INVERSEN Objekt-Rotation.\n",
        "    Simuliert, dass die Kamera sich um das statische Objekt bewegt.\n",
        "    euler_angles: tensor([rx, ry, rz]) der OBJEKT-Rotation in Radians ('sxyz').\n",
        "    \"\"\"\n",
        "    if trimesh is None:\n",
        "         logger.error(\"Trimesh nicht gefunden, kann Strahlen nicht rotieren.\")\n",
        "         return rays_o, rays_d # Gebe unrotierte Strahlen zurück\n",
        "\n",
        "    # 1. Erstelle die 4x4 Rotationsmatrix für das OBJEKT\n",
        "    R4_obj = euler_matrix(\n",
        "        float(object_euler_angles[0]),\n",
        "        float(object_euler_angles[1]),\n",
        "        float(object_euler_angles[2]),\n",
        "        \"sxyz\", # Konvention wie in Ihrem Code\n",
        "    )\n",
        "\n",
        "    # 2. Berechne die INVERSE dieser Rotation\n",
        "    # Die Rotation, die die Kamera machen müsste, um das rotierte Objekt zu sehen\n",
        "    R4_obj_inv = inverse_matrix(R4_obj)\n",
        "\n",
        "    # 3. Extrahiere 3x3 Rotationsanteil\n",
        "    R_inv = torch.from_numpy(R4_obj_inv[:3, :3]).to(rays_o.device).float()\n",
        "\n",
        "    # 4. Rotiere Ursprünge (rays_o) und Richtungen (rays_d) der KANONISCHEN Strahlen\n",
        "    # Wichtig: Richtige Matrixmultiplikations-Reihenfolge\n",
        "    ro_rotated = (R_inv @ rays_o.T).T\n",
        "    rd_rotated = (R_inv @ rays_d.T).T\n",
        "\n",
        "    return ro_rotated, rd_rotated\n",
        "\n",
        "# ---------- ENDE: Modifizierte Rotationsfunktion ----------\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 6. Weighted Ray Sampling (Unverändert)\n",
        "################################################################################\n",
        "def sample_rays_weighted(rays_o, rays_d, rgb, mask, original_shape, batch_size=1024):\n",
        "    H, W = original_shape\n",
        "    total_pixels = mask.shape[0]\n",
        "    pixels_per_view = H * W\n",
        "    if total_pixels == 0: raise ValueError(\"Cannot sample from empty tensors.\")\n",
        "    if H <= 0 or W <= 0 or pixels_per_view <= 0: raise ValueError(f\"Invalid original_shape H={H}, W={W}\")\n",
        "    if total_pixels % pixels_per_view != 0: num_views = 1\n",
        "    else: num_views = total_pixels // pixels_per_view\n",
        "\n",
        "    weights_list = []\n",
        "    kernel = torch.tensor([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]], device=mask.device).float().reshape(1, 1, 3, 3)\n",
        "\n",
        "    for view_idx in range(num_views):\n",
        "        start_idx = view_idx * pixels_per_view\n",
        "        end_idx = start_idx + pixels_per_view\n",
        "        view_mask = mask[start_idx:end_idx]\n",
        "        mask_2d = view_mask.reshape(1, 1, H, W)\n",
        "        edges = torch.abs(torch.nn.functional.conv2d(mask_2d.float(), kernel, padding=1)).squeeze()\n",
        "        edge_weights = edges.reshape(-1) + 0.1\n",
        "        fg_weights = (view_mask > 0.5).float() * 1.0 # Gewichtung angepasst\n",
        "        weights = edge_weights * 2.0 + fg_weights * 1.0\n",
        "        weights_list.append(weights)\n",
        "\n",
        "    weights = torch.cat(weights_list)\n",
        "    weights = torch.clamp(weights, min=1e-6)\n",
        "    p = weights / weights.sum()\n",
        "    num_available = p.shape[0]\n",
        "    effective_batch_size = min(batch_size, num_available)\n",
        "    if effective_batch_size <= 0: raise ValueError(\"Batch size or number of available rays is zero.\")\n",
        "    idx = torch.multinomial(p, effective_batch_size, replacement=True)\n",
        "    return rays_o[idx], rays_d[idx], rgb[idx], mask[idx]\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 7. Debug Rendering (Unverändert, aber braucht near/far)\n",
        "################################################################################\n",
        "@torch.no_grad()\n",
        "def debug_render(model,rays_o,rays_d,H,W,near,far,sigma_scale=1.0,N_samples=64,device=None,title_prefix=\"debug\",iteration=0,out_dir=\"debug_renders\"):\n",
        "    if device is None: device = rays_o.device\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    model.eval()\n",
        "    B = rays_o.shape[0]\n",
        "    if B == 0: logger.warning(f\"[{title_prefix} DEBUG RENDER] No rays provided at iter {iteration}.\"); return\n",
        "    chunk_size = 4096\n",
        "    all_rgb, all_alpha = [], []\n",
        "    for start in range(0, B, chunk_size):\n",
        "        end = min(start + chunk_size, B);\n",
        "        if start == end: continue\n",
        "        rgb_chunk, alpha_chunk = render_rays(model,rays_o[start:end],rays_d[start:end],near=near,far=far,sigma_scale=sigma_scale,N_samples=N_samples,white_bkgd=False)\n",
        "        all_rgb.append(rgb_chunk.cpu()); all_alpha.append(alpha_chunk.cpu())\n",
        "    if not all_rgb: logger.warning(f\"[{title_prefix} DEBUG RENDER] No results generated at iter {iteration}.\"); return\n",
        "    rgb_full = torch.cat(all_rgb, dim=0).reshape(H, W, 3).numpy()\n",
        "    alpha_full = torch.cat(all_alpha, dim=0).reshape(H, W).numpy()\n",
        "    # Save RGB\n",
        "    plt.figure(figsize=(6, 6)); plt.imshow(np.clip(rgb_full, 0, 1)); plt.title(f\"{title_prefix}_rgb_iter_{iteration}\"); plt.axis(\"off\"); rgb_path = os.path.join(out_dir, f\"{title_prefix}_rgb_iter_{iteration}.png\")\n",
        "    try: plt.savefig(rgb_path)\n",
        "    except Exception as e: logger.error(f\"Failed to save debug image {rgb_path}: {e}\")\n",
        "    plt.close()\n",
        "    # Save Alpha\n",
        "    plt.figure(figsize=(6, 6)); plt.imshow(alpha_full, cmap=\"gray\", vmin=0, vmax=1); plt.title(f\"{title_prefix}_alpha_iter_{iteration}\"); plt.axis(\"off\"); alpha_path = os.path.join(out_dir, f\"{title_prefix}_alpha_iter_{iteration}.png\")\n",
        "    try: plt.savefig(alpha_path)\n",
        "    except Exception as e: logger.error(f\"Failed to save debug image {alpha_path}: {e}\")\n",
        "    plt.close()\n",
        "    logger.info(f\"[{title_prefix} DEBUG RENDER] Saved debug images at iter {iteration} in {out_dir}/\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def debug_compare_mask_and_alpha(model,rays_o,rays_d,mask,H,W,near,far,sigma_scale=1.0,N_samples=64,device=None,title_prefix=\"debug\",iteration=0,out_dir=\"debug_renders\"):\n",
        "    if device is None: device = rays_o.device\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    model.eval()\n",
        "    B = rays_o.shape[0]\n",
        "    if B == 0 or mask.shape[0] == 0: logger.warning(f\"[{title_prefix} DEBUG MASK] No rays or mask provided at iter {iteration}.\"); return\n",
        "    if B != mask.shape[0]: logger.warning(f\"[{title_prefix} DEBUG MASK] Ray count ({B}) != mask count ({mask.shape[0]}) at iter {iteration}.\"); return\n",
        "    chunk_size = 4096\n",
        "    all_alpha = []\n",
        "    for start in range(0, B, chunk_size):\n",
        "        end = min(start + chunk_size, B);\n",
        "        if start == end: continue\n",
        "        _, alpha_chunk = render_rays(model,rays_o[start:end],rays_d[start:end],near=near,far=far,sigma_scale=sigma_scale,N_samples=N_samples)\n",
        "        all_alpha.append(alpha_chunk.cpu())\n",
        "    if not all_alpha: logger.warning(f\"[{title_prefix} DEBUG MASK] No alpha results generated at iter {iteration}.\"); return\n",
        "    alpha_full = torch.cat(all_alpha, dim=0).reshape(H, W).numpy()\n",
        "    mask_gt = mask.reshape(H, W).cpu().numpy()\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    axes[0].imshow(mask_gt, cmap=\"gray\", vmin=0, vmax=1); axes[0].set_title(f\"{title_prefix} GT Mask (iter={iteration})\"); axes[0].axis(\"off\")\n",
        "    axes[1].imshow(alpha_full, cmap=\"gray\", vmin=0, vmax=1); axes[1].set_title(f\"{title_prefix} Pred Alpha (iter={iteration})\"); axes[1].axis(\"off\")\n",
        "    compare_path = os.path.join(out_dir, f\"{title_prefix}_mask_vs_alpha_iter_{iteration}.png\")\n",
        "    try: plt.savefig(compare_path)\n",
        "    except Exception as e: logger.error(f\"Failed to save debug comparison image {compare_path}: {e}\")\n",
        "    plt.close(fig)\n",
        "    logger.info(f\"[{title_prefix} DEBUG MASK] Saved mask comparison at iter {iteration} in {out_dir}/\")\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 8. 3D Extraction via Marching Cubes (Unverändert)\n",
        "################################################################################\n",
        "def extract_3d_from_nerf(model, resolution=128, bound=1.0, sigma_threshold=5.0, sigma_scale=1.0, device=None, output_filename=\"nerf_reconstruction.stl\"):\n",
        "    if marching_cubes is None or trimesh is None: logger.error(\"[EXTRACT 3D] `skimage` or `trimesh` nicht gefunden.\"); return None\n",
        "    logger.info(f\"\\n[EXTRACT 3D] Führe Marching Cubes aus (Res={resolution}, Bound={bound}, Thresh={sigma_threshold})...\")\n",
        "    if device is None: device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "    grid_min, grid_max = -bound, bound\n",
        "    x = torch.linspace(grid_min, grid_max, resolution)\n",
        "    y = torch.linspace(grid_min, grid_max, resolution)\n",
        "    z = torch.linspace(grid_min, grid_max, resolution)\n",
        "    grid_coords = torch.stack(torch.meshgrid(x, y, z, indexing=\"ij\"), dim=-1)\n",
        "    coords_flat = grid_coords.reshape(-1, 3).to(device)\n",
        "    sigmas_flat = []\n",
        "    chunk_size = 32768\n",
        "    with torch.no_grad():\n",
        "        for i in trange(0, coords_flat.shape[0], chunk_size, desc=\"  Sigma abfragen\", leave=False):\n",
        "            sigma_chunk = torch.relu(model(coords_flat[i:i+chunk_size])[..., 3]) * sigma_scale\n",
        "            sigmas_flat.append(sigma_chunk.cpu())\n",
        "    sigma_volume = torch.cat(sigmas_flat).reshape(resolution, resolution, resolution).numpy()\n",
        "    vol_min, vol_max = sigma_volume.min(), sigma_volume.max()\n",
        "    vol_mean, vol_std = sigma_volume.mean(), sigma_volume.std()\n",
        "    logger.info(f\"  Sigma Volumen Stats: min={vol_min:.4f}, max={vol_max:.4f}, mean={vol_mean:.4f}, std={vol_std:.4f}\")\n",
        "    logger.info(f\"  Verwende Iso-Level (Threshold) = {sigma_threshold:.4f}\")\n",
        "    try:\n",
        "        verts, faces, normals, _ = marching_cubes(volume=sigma_volume, level=sigma_threshold)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"  Marching Cubes fehlgeschlagen: {e}\"); return None\n",
        "    if verts.shape[0] == 0: logger.warning(f\"  Marching Cubes erzeugte 0 Vertices bei Threshold {sigma_threshold}.\"); return None\n",
        "    verts_scaled = grid_min + verts * ( (grid_max - grid_min) / (resolution - 1) )\n",
        "    mesh = trimesh.Trimesh(vertices=verts_scaled, faces=faces, vertex_normals=normals)\n",
        "    try: mesh.export(output_filename); logger.info(f\"  --> Mesh gespeichert ({len(mesh.vertices)}V, {len(mesh.faces)}F) nach {output_filename}\")\n",
        "    except Exception as e: logger.error(f\"  Fehler beim Exportieren von Mesh nach {output_filename}: {e}\")\n",
        "    return mesh\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 9. Chamfer Distance (Unverändert)\n",
        "################################################################################\n",
        "def chamfer_distance(points1, points2):\n",
        "    if cKDTree is None: logger.error(\"`scipy` nicht gefunden.\"); return float('inf')\n",
        "    if points1 is None or points2 is None or len(points1) == 0 or len(points2) == 0: return float('inf')\n",
        "    tree1, tree2 = cKDTree(points1), cKDTree(points2)\n",
        "    dist1, _ = tree1.query(points2)\n",
        "    dist2, _ = tree2.query(points1)\n",
        "    return np.mean(dist1**2) + np.mean(dist2**2)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 10. Plot Meshes (Unverändert)\n",
        "################################################################################\n",
        "# Definition von plot_meshes (optional, wie im vorherigen Code)\n",
        "# ... (Code für plot_meshes hier einfügen, falls benötigt) ...\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 11. Training Loop (Unverändert, nimmt near/far entgegen)\n",
        "################################################################################\n",
        "def train_nerf(\n",
        "    model, rays_o_all, rays_d_all, target_pixels_all, mask_all,\n",
        "    near, far, # Explizite near/far bounds\n",
        "    image_shape, num_iterations=8000, batch_size=1024, learning_rate=5e-4,\n",
        "    lambda_photo=1.0, lambda_sil=1.0, lambda_shape=1e-3, lambda_density=0.1, lambda_smooth=0.05,\n",
        "    N_samples=128, sigma_scale=1.0, use_amp=True, debug_interval=1000, out_dir=\"debug_renders\", device=None\n",
        "):\n",
        "    H, W = image_shape\n",
        "    pixels_per_view = H * W\n",
        "    num_views = rays_o_all.shape[0] // pixels_per_view if pixels_per_view > 0 else 0\n",
        "    logger.info(f\"[TRAIN] Starte Training für {num_iterations} Iterationen.\")\n",
        "    logger.info(f\"[TRAIN] Views={num_views}, H={H}, W={W}, Total rays={rays_o_all.shape[0]}\")\n",
        "    logger.info(f\"[TRAIN] Near={near:.4f}, Far={far:.4f}\") # Logge die verwendeten Bounds\n",
        "    logger.info(f\"[TRAIN] Loss Lambdas: Photo={lambda_photo}, Sil={lambda_sil}, Shape={lambda_shape}, Dens={lambda_density}, Smooth={lambda_smooth}\")\n",
        "\n",
        "    if device is None: device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device); model.train()\n",
        "    rays_o_all, rays_d_all = rays_o_all.to(device), rays_d_all.to(device)\n",
        "    target_pixels_all, mask_all = target_pixels_all.to(device), mask_all.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=500) # Korrigierte Zeile\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "    losses = []\n",
        "    best_loss = float(\"inf\")\n",
        "    pbar = trange(num_iterations, desc=\"Training NeRF\", unit=\"iter\")\n",
        "\n",
        "    for i in pbar:\n",
        "        optimizer.zero_grad()\n",
        "        try:\n",
        "            rays_o_batch, rays_d_batch, rgb_batch, mask_batch = sample_rays_weighted(\n",
        "                rays_o_all, rays_d_all, target_pixels_all, mask_all, (H, W), batch_size)\n",
        "        except ValueError as e: logger.error(f\"Ray sampling failed: {e}\"); break\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "            rgb_map, alpha_map = render_rays(model, rays_o_batch, rays_d_batch, near=near, far=far, N_samples=N_samples, sigma_scale=sigma_scale) # Verwende N_samples hier\n",
        "            photo_loss = torch.mean((rgb_map - rgb_batch) ** 2)\n",
        "            sil_loss_val = silhouette_loss(alpha_map, mask_batch)\n",
        "            shape_loss_val = spherical_prior_loss(model, sigma_scale=sigma_scale, device=device) if lambda_shape > 0 else torch.tensor(0.0, device=device)\n",
        "            dens_loss_val = foreground_density_loss(alpha_map, mask_batch) if lambda_density > 0 else torch.tensor(0.0, device=device)\n",
        "            smooth_loss_val = smoothness_prior_loss(model, sigma_scale=sigma_scale, device=device) if lambda_smooth > 0 else torch.tensor(0.0, device=device)\n",
        "            total_loss = (lambda_photo * photo_loss + lambda_sil * sil_loss_val + lambda_shape * shape_loss_val + lambda_density * dens_loss_val + lambda_smooth * smooth_loss_val)\n",
        "\n",
        "        scaler.scale(total_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step(total_loss)\n",
        "        current_loss = total_loss.item()\n",
        "        losses.append(current_loss)\n",
        "        pbar.set_description(f\"Iter {i+1}/{num_iterations} | Loss: {current_loss:.4f} LR: {optimizer.param_groups[0]['lr']:.1e}\")\n",
        "\n",
        "        if current_loss < best_loss: best_loss = current_loss; torch.save(model.state_dict(), \"nerf_best_model.pth\")\n",
        "\n",
        "        if (i + 1) % debug_interval == 0 or i == num_iterations - 1:\n",
        "            logger.info(f\"\\n[DEBUG] Rendere Debug-Ansichten bei Iteration {i + 1}...\")\n",
        "            model.eval()\n",
        "            for view_idx in range(num_views):\n",
        "                 start_idx, end_idx = view_idx * pixels_per_view, (view_idx + 1) * pixels_per_view\n",
        "                 view_prefix = f\"view{view_idx}\"\n",
        "                 view_rays_o, view_rays_d = rays_o_all[start_idx:end_idx], rays_d_all[start_idx:end_idx]\n",
        "                 view_mask = mask_all[start_idx:end_idx]\n",
        "                 debug_render(model, view_rays_o, view_rays_d, H, W, near, far, sigma_scale, N_samples=128, device=device, title_prefix=view_prefix, iteration=i + 1, out_dir=out_dir)\n",
        "                 debug_compare_mask_and_alpha(model, view_rays_o, view_rays_d, view_mask, H, W, near, far, sigma_scale, N_samples=128, device=device, title_prefix=view_prefix, iteration=i + 1, out_dir=out_dir)\n",
        "            ckpt_path = f\"nerf_checkpoint_{i + 1}.pth\"; torch.save(model.state_dict(), ckpt_path); logger.info(f\"[TRAIN] Checkpoint {ckpt_path} gespeichert\")\n",
        "            model.train()\n",
        "            logger.info(\"[DEBUG] Debug-Rendering beendet.\")\n",
        "\n",
        "    logger.info(\"[TRAIN] Training beendet.\")\n",
        "    if os.path.exists(\"nerf_best_model.pth\"): logger.info(\"Lade besten Modellzustand.\"); model.load_state_dict(torch.load(\"nerf_best_model.pth\", map_location=device))\n",
        "    return model, losses\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# 12. Main Block (Angepasst für STARKE ANNAHMEN)\n",
        "################################################################################\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Setup\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info(f\"[SYS] Verwende Gerät: {device}\")\n",
        "\n",
        "    # --- Annahmen-basierte Konfiguration ---\n",
        "    ASSUMED_DISTANCE = 1.5\n",
        "    ASSUMED_PARALLEL_SCALE = 0.8\n",
        "    ASSUMED_SCENE_BOUND = 1.0\n",
        "    ASSUMED_NEAR = ASSUMED_DISTANCE - ASSUMED_SCENE_BOUND # Angenommene nahe Grenze\n",
        "    ASSUMED_FAR = ASSUMED_DISTANCE + ASSUMED_SCENE_BOUND   # Angenommene ferne Grenze\n",
        "    logger.warning(\"*\" * 60)\n",
        "    logger.warning(\"!!! ACHTUNG: VERWENDUNG VON STARKEN ANNAHMEN STATT METADATEN !!!\")\n",
        "    logger.warning(f\"!!! Annahmen: Dist={ASSUMED_DISTANCE}, Scale={ASSUMED_PARALLEL_SCALE}, Near={ASSUMED_NEAR:.2f}, Far={ASSUMED_FAR:.2f} !!!\")\n",
        "    logger.warning(\"!!! Ergebnisse sind wahrscheinlich geometrisch ungenau!       !!!\")\n",
        "    logger.warning(\"*\" * 60)\n",
        "\n",
        "    # --- Lade Daten über Dataset-Klasse ---\n",
        "    # (Stellt sicher, dass get_train_test_split verfügbar ist)\n",
        "    if get_train_test_split is None:\n",
        "        logger.error(\"PollenDataset / get_train_test_split nicht verfügbar. Abbruch.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    image_transform = transforms.ToTensor()\n",
        "    try:\n",
        "        dataset, train_ids, test_ids = get_train_test_split(\n",
        "            image_transforms=image_transform,\n",
        "            mesh_transforms=None, # Kein GT-Mesh für Training benötigt\n",
        "            device=device, # Lade direkt auf GPU, falls möglich\n",
        "        )\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Fehler beim Initialisieren des Datasets: {e}\", exc_info=True)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # 2) Wähle ein Sample\n",
        "    if not train_ids:\n",
        "        logger.error(\"Keine Trainings-IDs gefunden.\")\n",
        "        sys.exit(1)\n",
        "    sample_idx = train_ids[0] # Nimm das erste Trainingsbeispiel\n",
        "    try:\n",
        "        (left_img, right_img), gt_points, object_rotations_rad, voxels = dataset[sample_idx]\n",
        "        # Versuche, einen Sample-Namen zu bekommen (optional, für Dateinamen)\n",
        "        sample_name = getattr(dataset, 'get_sample_name', lambda idx: f\"sample_{idx}\")(sample_idx)\n",
        "\n",
        "        logger.info(f\"[DATA] Lade Sample #{sample_idx} ({sample_name})\")\n",
        "        logger.info(f\"  Bilder: {left_img.shape}, {right_img.shape}\")\n",
        "        logger.info(f\"  GT Punkte: {gt_points.shape if hasattr(gt_points, 'shape') else 'N/A'}\")\n",
        "        logger.info(f\"  Objekt Rotation (rad): {object_rotations_rad.tolist()}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Fehler beim Laden von Sample Index {sample_idx}: {e}\", exc_info=True)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # 3) Stelle 3 Kanäle sicher & normalisiere Pixel auf [0, 1]\n",
        "    def preprocess_image(img):\n",
        "        if img.ndim == 2: img = img.unsqueeze(0) # Füge Kanal hinzu\n",
        "        if img.shape[0] == 1: img = img.repeat(3, 1, 1) # Wiederhole für RGB\n",
        "        if img.max() > 1.1: # Geringe Toleranz für Float-Ungenauigkeiten\n",
        "            logger.warning(f\" Bild Max > 1 ({img.max():.2f}), normalisiere mit 255.\")\n",
        "            img = img / 255.0\n",
        "        return torch.clamp(img, 0.0, 1.0) # Stelle sicher, dass es im Bereich [0,1] liegt\n",
        "\n",
        "    left_img = preprocess_image(left_img).to(device)\n",
        "    right_img = preprocess_image(right_img).to(device)\n",
        "\n",
        "    # 4) Inferiere Höhe und Breite\n",
        "    # Annahme: Beide Bilder haben die gleiche Größe\n",
        "    if left_img.shape[1:] != right_img.shape[1:]:\n",
        "         logger.error(\"Linkes und rechtes Bild haben unterschiedliche Dimensionen!\")\n",
        "         sys.exit(1)\n",
        "    H, W = left_img.shape[1], left_img.shape[2]\n",
        "    logger.info(f\"[DATA] Bild Dimensionen: H={H}, W={W}\")\n",
        "\n",
        "    # 5) Berechne Silhouetten (Masken)\n",
        "    # Verwende direkt normalisierte Bilder\n",
        "    mask_threshold = 0.1 # Schwellwert für Maske (angepasst, ggf. tunen)\n",
        "    left_gray = left_img.mean(dim=0) # Reduziere auf Graustufen\n",
        "    right_gray = right_img.mean(dim=0)\n",
        "    # Kleiner Weichzeichner/Pooling kann helfen, Rauschen zu reduzieren\n",
        "    pool = lambda x: torch.nn.functional.avg_pool2d(x.reshape(1,1,H,W), kernel_size=3, stride=1, padding=1).squeeze()\n",
        "    # Erstelle binäre Maske\n",
        "    left_mask = (pool(left_gray) > mask_threshold).float().reshape(-1)\n",
        "    right_mask = (pool(right_gray) > mask_threshold).float().reshape(-1)\n",
        "\n",
        "    # 6) Flache Pixelwerte für Training\n",
        "    left_img_flat = left_img.permute(1, 2, 0).reshape(-1, 3)\n",
        "    right_img_flat = right_img.permute(1, 2, 0).reshape(-1, 3)\n",
        "\n",
        "    # --- 7) GENERIERE STRAHLEN BASIEREND AUF STARKEN ANNAHMEN ---\n",
        "    logger.info(\"Generiere KANONISCHE Strahlen basierend auf festen Annahmen...\")\n",
        "    rays_o_f_can, rays_d_f_can, rays_o_s_can, rays_d_s_can = get_rays_fixed_assumptions(H, W, device=device)\n",
        "\n",
        "    logger.info(\"Rotiere kanonische Strahlen mit INVERSER Objekt-Rotation...\")\n",
        "    # Wende INVERSE Objekt-Rotation auf KANONISCHE Kamera-Strahlen an\n",
        "    rays_o_front, rays_d_front = rotate_rays_inverse_object(rays_o_f_can, rays_d_f_can, object_rotations_rad)\n",
        "    rays_o_side, rays_d_side = rotate_rays_inverse_object(rays_o_s_can, rays_d_s_can, object_rotations_rad)\n",
        "\n",
        "    # 8) Kombiniere Daten für beide Ansichten\n",
        "    rays_o_all = torch.cat([rays_o_front, rays_o_side], dim=0)\n",
        "    rays_d_all = torch.cat([rays_d_front, rays_d_side], dim=0)\n",
        "    target_pixels_all = torch.cat([left_img_flat, right_img_flat], dim=0)\n",
        "    mask_all = torch.cat([left_mask, right_mask], dim=0)\n",
        "    logger.info(f\"Gesamtzahl Strahlen für Training: {rays_o_all.shape[0]}\")\n",
        "\n",
        "\n",
        "    # 9) Initialisiere NeRF & Trainiere\n",
        "    # Hyperparameter für Training (ggf. anpassen)\n",
        "    train_iterations = 10000\n",
        "    train_batch_size = 2048\n",
        "    train_lr = 5e-4\n",
        "    train_lambda_photo = 1.0\n",
        "    train_lambda_sil = 1.0\n",
        "    train_lambda_shape = 1e-4 # Ggf. niedriger starten bei Annahmen\n",
        "    train_lambda_density = 0.05\n",
        "    train_lambda_smooth = 1e-4\n",
        "    train_n_samples = 128 # Samples pro Strahl im Training\n",
        "    train_sigma_scale = 1.0\n",
        "    train_debug_interval = 2000\n",
        "\n",
        "    model = NeRF(D=6, W=128, L=4).to(device) # Kleineres Modell für schnelleres Testen?\n",
        "    model, losses = train_nerf(\n",
        "        model,\n",
        "        rays_o_all,\n",
        "        rays_d_all,\n",
        "        target_pixels_all,\n",
        "        mask_all,\n",
        "        near=ASSUMED_NEAR, # Verwende angenommene Bounds\n",
        "        far=ASSUMED_FAR,   # Verwende angenommene Bounds\n",
        "        image_shape=(H, W),\n",
        "        num_iterations=train_iterations,\n",
        "        batch_size=train_batch_size,\n",
        "        learning_rate=train_lr,\n",
        "        lambda_photo=train_lambda_photo,\n",
        "        lambda_sil=train_lambda_sil,\n",
        "        lambda_shape=train_lambda_shape,\n",
        "        lambda_density=train_lambda_density,\n",
        "        lambda_smooth=train_lambda_smooth,\n",
        "        N_samples=train_n_samples,\n",
        "        sigma_scale=train_sigma_scale,\n",
        "        use_amp=torch.cuda.is_available(),\n",
        "        debug_interval=train_debug_interval,\n",
        "        out_dir=f\"debug_{sample_name}_ASSUMED\", # Markiere Debug-Ordner\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # 10) Extrahiere Mesh & optionaler Vergleich\n",
        "    if marching_cubes and trimesh:\n",
        "        mesh_filename = f\"./{sample_name}_reconstruction_ASSUMED.stl\"\n",
        "        pred_mesh = extract_3d_from_nerf(\n",
        "            model,\n",
        "            resolution=192, # Höhere Auflösung für Mesh\n",
        "            bound=ASSUMED_SCENE_BOUND, # Bound passend zu Annahmen\n",
        "            sigma_threshold=10.0, # Schwellwert ggf. anpassen\n",
        "            sigma_scale=train_sigma_scale,\n",
        "            device=device,\n",
        "            output_filename=mesh_filename\n",
        "        )\n",
        "        # Optional: Lade GT Punkte und berechne Chamfer Distanz\n",
        "        if pred_mesh is not None and hasattr(gt_points, 'cpu'):\n",
        "            try:\n",
        "                pred_points = pred_mesh.sample(5000)\n",
        "                gt_points_np = gt_points.cpu().numpy()\n",
        "                if gt_points_np.shape[0] > 0:\n",
        "                     cd = chamfer_distance(pred_points, gt_points_np)\n",
        "                     logger.info(f\"\\n[RESULT] Chamfer Distanz (vs GT Punkte): {cd:.6f}\")\n",
        "                else:\n",
        "                     logger.warning(\"Keine GT Punkte zum Vergleich verfügbar.\")\n",
        "            except Exception as e:\n",
        "                 logger.error(f\"Fehler bei Chamfer-Distanz-Berechnung: {e}\")\n",
        "    else:\n",
        "        logger.warning(\"Mesh-Extraktion übersprungen, da optionale Pakete fehlen.\")\n",
        "\n",
        "    logger.info(f\"\\nVerarbeitung für Sample {sample_name} (mit Annahmen) beendet.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7 Findings & Failure analysis\n",
        "\n",
        "\n",
        "We typically observe **scale drift** (mesh ~2× larger) and missing spikes because two views under‑constrain the density field.  Nevertheless, a coarse ellipsoidal hull is recovered.\n",
        "\n",
        "# 8 Conclusion & next steps\n",
        "\n",
        "*Even this bare‑bones NeRF recovers a *hint* of the true shape but fails at fine detail and absolute scale.*  Next experiments will add **geometric priors** (radial profile, symmetry) and **multi‑scale sampling** to address these issues.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
