{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"NeRF Exploration: Two-View Reconstruction of Pollen Grains\"\n",
        "author: \"Nils Fahrni, Etienne Roulet\"\n",
        "date: \"2025-03-28\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    code-fold: true\n",
        "    code-line-numbers: true\n",
        "    embed-resources: true\n",
        "    self-contained-math: true\n",
        "  ipynb: default\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "# Abstract\n",
        "\n",
        "abstract desc\n",
        "\n",
        "# 1 Introduction\n",
        "\n",
        "Text here\n",
        "\n",
        "**Key questions**\n",
        "\n",
        "- Text\n",
        "- Text\n",
        "- Text\n",
        "\n",
        "\n",
        "# 2 Environment check\n"
      ],
      "id": "70e41797"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ],
      "id": "b7ef7519",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper"
      ],
      "id": "e8201109"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "################################################################################\n",
        "# 8. 3D Extraction via Marching Cubes\n",
        "################################################################################\n",
        "def extract_3d_from_nerf(\n",
        "    model, resolution=128, bound=1.0, sigma_scale=2.0, device=None\n",
        "):\n",
        "    print(\"\\n[EXTRACT 3D] Running marching cubes...\")\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    model.eval()\n",
        "    coords = (\n",
        "        torch.stack(\n",
        "            torch.meshgrid(\n",
        "                torch.linspace(-bound, bound, resolution),\n",
        "                torch.linspace(-bound, bound, resolution),\n",
        "                torch.linspace(-bound, bound, resolution),\n",
        "                indexing=\"ij\",\n",
        "            ),\n",
        "            dim=-1,\n",
        "        )\n",
        "        .reshape(-1, 3)\n",
        "        .to(device)\n",
        "    )\n",
        "\n",
        "    sigmas = []\n",
        "    chunk = 4096\n",
        "    with torch.no_grad():\n",
        "        for start in range(0, coords.shape[0], chunk):\n",
        "            out = model(coords[start : start + chunk])\n",
        "            sigma_part = torch.relu(out[..., 3]) * sigma_scale\n",
        "            sigmas.append(sigma_part.cpu())\n",
        "    sigma_volume = torch.cat(sigmas).reshape(resolution, resolution, resolution).numpy()\n",
        "\n",
        "    vol_min, vol_max = sigma_volume.min(), sigma_volume.max()\n",
        "    vol_mean, vol_std = sigma_volume.mean(), sigma_volume.std()\n",
        "    print(\n",
        "        f\"  Sigma volume stats: min={vol_min:.4f}, max={vol_max:.4f}, mean={vol_mean:.4f}, std={vol_std:.4f}\"\n",
        "    )\n",
        "\n",
        "    level = vol_mean + 0.3 * vol_std\n",
        "    if (level <= vol_min) or (level >= vol_max):\n",
        "        level = vol_mean\n",
        "    print(f\"  Using iso-level={level:.4f}\")\n",
        "\n",
        "    try:\n",
        "        verts, faces, normals, _ = marching_cubes(sigma_volume, level=level)\n",
        "        # Rescale to [-bound, bound]\n",
        "        verts = (verts / resolution) * (2.0 * bound) - bound\n",
        "        mesh = trimesh.Trimesh(vertices=verts, faces=faces, normals=normals)\n",
        "        mesh.export(\"nerf_reconstruction.stl\")\n",
        "        print(\"  --> Saved mesh to nerf_reconstruction.stl\")\n",
        "        return mesh\n",
        "    except Exception as e:\n",
        "        print(\"  Marching cubes error:\", e)\n",
        "        print(\"  Trying fallback iso-level...\")\n",
        "        try:\n",
        "            fallback_level = vol_mean + 0.25 * vol_std\n",
        "            verts, faces, normals, _ = marching_cubes(\n",
        "                sigma_volume, level=fallback_level\n",
        "            )\n",
        "            verts = (verts / resolution) * (2.0 * bound) - bound\n",
        "            mesh = trimesh.Trimesh(vertices=verts, faces=faces, normals=normals)\n",
        "            mesh.export(\"nerf_reconstruction_fallback.stl\")\n",
        "            print(\"  --> Saved fallback mesh to nerf_reconstruction_fallback.stl\")\n",
        "            return mesh\n",
        "        except Exception as e2:\n",
        "            print(\"  Fallback also failed:\", e2)\n",
        "            return None"
      ],
      "id": "245f189e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3 Methodology\n",
        "\n",
        "## 3.1 Simple NeRF Exploration\n"
      ],
      "id": "112bd207"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "from scipy.spatial import cKDTree\n",
        "from skimage.measure import marching_cubes\n",
        "import trimesh\n",
        "\n",
        "# If you have the data package\n",
        "sys.path.append(\"..\")\n",
        "try:\n",
        "    from data.pollen_dataset import PollenDataset, get_train_test_split\n",
        "except ImportError:\n",
        "    PollenDataset = None\n",
        "    get_train_test_split = None\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def positional_encoding(x, L=4):\n",
        "    out = [x]\n",
        "    for i in range(L):\n",
        "        for fn in (torch.sin, torch.cos):\n",
        "            out.append(fn((2.0**i) * np.pi * x))\n",
        "    return torch.cat(out, dim=-1)\n",
        "\n",
        "class NeRF(nn.Module):\n",
        "    def __init__(self, D=6, W=128, L=4):\n",
        "        super().__init__()\n",
        "        self.L = L\n",
        "        in_ch = 3 * (2*L + 1)\n",
        "        layers = [nn.Linear(in_ch, W)] + [nn.Linear(W, W) for _ in range(D-1)]\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.out = nn.Linear(W,4)\n",
        "        with torch.no_grad():\n",
        "            self.out.bias[3] = 0.1\n",
        "    def forward(self, x):\n",
        "        x_enc = positional_encoding(x, self.L)\n",
        "        h = x_enc\n",
        "        for l in self.layers:\n",
        "            h = torch.relu(l(h))\n",
        "        return self.out(h)\n",
        "\n",
        "def render_rays(model, rays_o, rays_d, near=0.5, far=1.5, N_samples=128, sigma_scale=1.0):\n",
        "    device = rays_o.device\n",
        "    z_vals = torch.linspace(near, far, N_samples, device=device)\n",
        "    pts = rays_o[:,None,:] + rays_d[:,None,:]*z_vals[None,:,None]\n",
        "    raw = model(pts.reshape(-1,3)).reshape(pts.shape[0],N_samples,4)\n",
        "    rgb = torch.sigmoid(raw[...,:3])\n",
        "    sigma = torch.relu(raw[...,3])*sigma_scale\n",
        "    deltas = torch.cat([z_vals[1:]-z_vals[:-1], torch.tensor([1e10],device=device)])\n",
        "    deltas = deltas[None,:].expand(sigma.shape)\n",
        "    alpha = 1 - torch.exp(-sigma*deltas)\n",
        "    T = torch.cumprod(torch.cat([torch.ones((sigma.shape[0],1),device=device), 1-alpha+1e-10],-1),-1)[:,:-1]\n",
        "    weights = alpha * T\n",
        "    rgb_map = torch.sum(weights[...,None]*rgb,1)\n",
        "    alpha_map = torch.sum(weights,1)\n",
        "    return rgb_map, alpha_map\n",
        "\n",
        "def silhouette_loss(alpha, mask):\n",
        "    return torch.mean((alpha - mask)**2)\n",
        "\n",
        "def get_rays(H, W, focal=300.0):\n",
        "    i,j = torch.meshgrid(torch.linspace(0,W-1,W), torch.linspace(0,H-1,H), indexing='xy')\n",
        "    dirs = torch.stack([(i-W/2)/focal, -(j-H/2)/focal, -torch.ones_like(i)],-1)\n",
        "    rays_d = dirs/torch.norm(dirs,dim=-1,keepdim=True)\n",
        "    rays_o = torch.zeros_like(rays_d)\n",
        "    return rays_o.reshape(-1,3), rays_d.reshape(-1,3)\n",
        "\n",
        "def rotate_rays(o,d,angles):\n",
        "    from trimesh.transformations import euler_matrix\n",
        "    R4 = euler_matrix(float(angles[0]),float(angles[1]),float(angles[2]),'sxyz')\n",
        "    R = torch.from_numpy(R4[:3,:3]).to(o.device).float()\n",
        "    return (R@o.T).T, (R@d.T).T\n",
        "\n",
        "def sample_rays(rays_o, rays_d, pixels, mask, batch_size=1024):\n",
        "    N = mask.shape[0]\n",
        "    idx = torch.randint(0,N,(batch_size,),device=mask.device)\n",
        "    return rays_o[idx], rays_d[idx], pixels[idx], mask[idx]\n",
        "\n",
        "def train_nerf(model, rays_o_all, rays_d_all, target_pixels_all, mask_all,\n",
        "               image_shape, num_iterations=5000, device=None):\n",
        "    if device is None: device = next(model.parameters()).device\n",
        "    opt = optim.Adam(model.parameters(),lr=5e-4)\n",
        "    for _ in trange(num_iterations, desc=\"Training NeRF\"):\n",
        "        opt.zero_grad()\n",
        "        ro, rd, pix, m = sample_rays(rays_o_all, rays_d_all, target_pixels_all, mask_all, 1024)\n",
        "        rgb_hat, alpha_hat = render_rays(model,ro,rd)\n",
        "        loss = torch.mean((rgb_hat - pix)**2) + silhouette_loss(alpha_hat, m)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    return model\n",
        "\n",
        "# Main\n",
        "if __name__=='__main__':\n",
        "    dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"Device:\", dev)\n",
        "    tf = transforms.ToTensor()\n",
        "    dataset, train_ids, _ = get_train_test_split(image_transforms=tf, device=dev)\n",
        "    (l_img,r_img), gt_points, rot, _ = dataset[train_ids[0]]\n",
        "    # ensure 3-channel & normalize\n",
        "    if l_img.ndim == 2:\n",
        "        l_img = l_img.unsqueeze(0)\n",
        "    if l_img.shape[0] == 1:\n",
        "        l_img = l_img.repeat(3, 1, 1)\n",
        "    if l_img.max() > 1.0:\n",
        "        l_img = l_img / 255.0\n",
        "\n",
        "    if r_img.ndim == 2:\n",
        "        r_img = r_img.unsqueeze(0)\n",
        "    if r_img.shape[0] == 1:\n",
        "        r_img = r_img.repeat(3, 1, 1)\n",
        "    if r_img.max() > 1.0:\n",
        "        r_img = r_img / 255.0\n",
        "\n",
        "    # infer height and width\n",
        "    H, W = l_img.shape[1], l_img.shape[2]\n",
        "    # compute silhouettes\n",
        "    left_gray = l_img.mean(0,keepdim=True)\n",
        "    right_gray= r_img.mean(0,keepdim=True)\n",
        "    pool = lambda x: torch.nn.functional.avg_pool2d(x.unsqueeze(0),5,1,2).squeeze()\n",
        "    lm = (pool(left_gray)>0.2).float().reshape(-1)\n",
        "    rm = (pool(right_gray)>0.2).float().reshape(-1)\n",
        "    mask_all = torch.cat([lm, rm],0).to(dev)\n",
        "    # flatten pixels\n",
        "    lf = l_img.permute(1,2,0).reshape(-1,3)\n",
        "    rf = r_img.permute(1,2,0).reshape(-1,3)\n",
        "    target_pixels_all = torch.cat([lf,rf],0).to(dev)\n",
        "    # rays\n",
        "    ro_f, rd_f = get_rays(H,W)\n",
        "    ro1, rd1 = rotate_rays(ro_f, rd_f, rot)\n",
        "    ro2, rd2 = rotate_rays(ro_f, rd_f, rot)\n",
        "    rays_o_all = torch.cat([ro1,ro2],0).to(dev)\n",
        "    rays_d_all = torch.cat([rd1,rd2],0).to(dev)\n",
        "    # train\n",
        "    model = NeRF().to(dev)\n",
        "    model = train_nerf(model, rays_o_all, rays_d_all, target_pixels_all, mask_all, (H,W), device=dev)\n",
        "    # extract & save mesh\n",
        "    mesh = extract_3d_from_nerf(model, resolution=128, bound=1.0, sigma_scale=1.0, device=dev)\n",
        "    mesh.export('./nerf/baseline_recon.stl')\n",
        "    print('Done.')"
      ],
      "id": "bf9ee03f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4 More complex NeRF exploration\n",
        "\n",
        "## Implementation\n",
        "\n",
        "## 5 Strong Shape Prior\n",
        "## 5.1 Implementation\n",
        "\n",
        "# 6 Mesh extraction & evaluation\n"
      ],
      "id": "576ad38b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7 Findings & Failure analysis\n",
        "\n",
        "\n",
        "We typically observe **scale drift** (mesh ~2× larger) and missing spikes because two views under‑constrain the density field.  Nevertheless, a coarse ellipsoidal hull is recovered.\n",
        "\n",
        "# 8 Conclusion & next steps\n",
        "\n",
        "*Even this bare‑bones NeRF recovers a *hint* of the true shape but fails at fine detail and absolute scale.*  Next experiments will add **geometric priors** (radial profile, symmetry) and **multi‑scale sampling** to address these issues.\n"
      ],
      "id": "66a2139e"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "c:\\Users\\super\\Documents\\GitHub\\sequoia\\.venv\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}