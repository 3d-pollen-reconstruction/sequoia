{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.measure import marching_cubes\n",
    "import trimesh\n",
    "\n",
    "# If you have the data package\n",
    "sys.path.append(\"..\")\n",
    "try:\n",
    "    from data.pollen_dataset import PollenDataset, get_train_test_split\n",
    "except ImportError:\n",
    "    PollenDataset = None\n",
    "    get_train_test_split = None\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. Positional Encoding (Reduced Frequencies)\n",
    "# -----------------------------------------------------------------------------\n",
    "def positional_encoding(x, L=4):\n",
    "    out = [x]\n",
    "    for i in range(L):\n",
    "        for fn in (torch.sin, torch.cos):\n",
    "            out.append(fn((2.0**i) * np.pi * x))\n",
    "    return torch.cat(out, dim=-1)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. NeRF Model\n",
    "# -----------------------------------------------------------------------------\n",
    "class NeRF(nn.Module):\n",
    "    def __init__(self, D=6, W=128, L=4):\n",
    "        super(NeRF, self).__init__()\n",
    "        self.L = L\n",
    "        in_ch = 3 * (2 * L + 1)\n",
    "        layers = [nn.Linear(in_ch, W)] + [nn.Linear(W, W) for _ in range(D - 1)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.output_layer = nn.Linear(W, 4)\n",
    "        with torch.no_grad():\n",
    "            self.output_layer.bias[3] = 0.1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = positional_encoding(x, self.L)\n",
    "        h = x_enc\n",
    "        for l in self.layers:\n",
    "            h = torch.relu(l(h))\n",
    "        return self.output_layer(h)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. Render Rays\n",
    "# -----------------------------------------------------------------------------\n",
    "def render_rays(\n",
    "    model, rays_o, rays_d, near=0.5, far=1.5, N_samples=128, sigma_scale=1.0\n",
    "):\n",
    "    device = rays_o.device\n",
    "    z_vals = torch.linspace(near, far, N_samples, device=device)\n",
    "    pts = rays_o[:, None, :] + rays_d[:, None, :] * z_vals[None, :, None]\n",
    "    raw = model(pts.reshape(-1, 3)).reshape(pts.shape[0], N_samples, 4)\n",
    "    rgb = torch.sigmoid(raw[..., :3])\n",
    "    sigma = torch.relu(raw[..., 3]) * sigma_scale\n",
    "    deltas = torch.cat([z_vals[1:] - z_vals[:-1], torch.tensor([1e10], device=device)])\n",
    "    deltas = deltas[None, :].expand(sigma.shape)\n",
    "    alpha = 1.0 - torch.exp(-sigma * deltas)\n",
    "    T = torch.cumprod(\n",
    "        torch.cat(\n",
    "            [torch.ones((sigma.shape[0], 1), device=device), 1 - alpha + 1e-10], dim=-1\n",
    "        ),\n",
    "        dim=-1,\n",
    "    )[:, :-1]\n",
    "    weights = alpha * T\n",
    "    rgb_map = torch.sum(weights[..., None] * rgb, dim=1)\n",
    "    alpha_map = torch.sum(weights, dim=1)\n",
    "    return rgb_map, alpha_map\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. Losses\n",
    "# -----------------------------------------------------------------------------\n",
    "def silhouette_loss(alpha, mask):\n",
    "    return torch.mean((alpha - mask) ** 2)\n",
    "\n",
    "\n",
    "def spherical_prior_loss(\n",
    "    model, num_samples=2000, bound=1.0, desired_radius=0.6, sigma_scale=2.0, device=None\n",
    "):\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "    coords = torch.rand(num_samples, 3, device=device) * (2 * bound) - bound\n",
    "    sigma = torch.relu(model(coords)[..., 3]) * sigma_scale\n",
    "    d = torch.norm(coords, dim=1)\n",
    "    return torch.mean(sigma * (d - desired_radius) ** 2)\n",
    "\n",
    "\n",
    "def foreground_density_loss(alpha, mask, target_density=1.0):\n",
    "    D = -torch.log(1 - alpha + 1e-6)\n",
    "    fg = mask > 0.5\n",
    "    if fg.sum() > 0:\n",
    "        return torch.mean(torch.clamp(target_density - D[fg], min=0.0))\n",
    "    return torch.tensor(0.0, device=alpha.device)\n",
    "\n",
    "\n",
    "def smoothness_prior_loss(\n",
    "    model, num_samples=2000, bound=1.0, offset=0.01, sigma_scale=2.0, device=None\n",
    "):\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "    coords = torch.rand(num_samples, 3, device=device) * (2 * bound) - bound\n",
    "    sigma0 = torch.relu(model(coords)[..., 3]) * sigma_scale\n",
    "    offsets = torch.tensor(\n",
    "        [\n",
    "            [offset, 0, 0],\n",
    "            [-offset, 0, 0],\n",
    "            [0, offset, 0],\n",
    "            [0, -offset, 0],\n",
    "            [0, 0, offset],\n",
    "            [0, 0, -offset],\n",
    "        ],\n",
    "        device=device,\n",
    "    )\n",
    "    diffs = []\n",
    "    for off in offsets:\n",
    "        sigma1 = torch.relu(model(coords + off)[..., 3]) * sigma_scale\n",
    "        diffs.append(torch.mean((sigma0 - sigma1) ** 2))\n",
    "    return sum(diffs) / len(diffs)\n",
    "\n",
    "\n",
    "# New strong priors:\n",
    "def radial_profile_loss(\n",
    "    model,\n",
    "    num_samples=5000,\n",
    "    bound=1.0,\n",
    "    desired_radius=0.6,\n",
    "    sigma_scale=2.0,\n",
    "    width=0.05,\n",
    "    device=None,\n",
    "):\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "    coords = (torch.rand(num_samples, 3, device=device) * 2 - 1) * bound\n",
    "    sigma = torch.relu(model(coords)[..., 3]) * sigma_scale\n",
    "    d = torch.norm(coords, dim=1)\n",
    "    target = torch.exp(-0.5 * ((d - desired_radius) / width) ** 2)\n",
    "    return torch.mean((sigma - target) ** 2)\n",
    "\n",
    "\n",
    "def symmetry_loss(model, num_samples=5000, bound=1.0, sigma_scale=2.0, device=None):\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "    coords = (torch.rand(num_samples, 3, device=device) * 2 - 1) * bound\n",
    "    sigma0 = torch.relu(model(coords)[..., 3]) * sigma_scale\n",
    "    losses = []\n",
    "    for axis in range(3):\n",
    "        refl = coords.clone()\n",
    "        refl[:, axis] *= -1\n",
    "        sigma1 = torch.relu(model(refl)[..., 3]) * sigma_scale\n",
    "        losses.append(torch.mean((sigma0 - sigma1) ** 2))\n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. Rays & Rotation\n",
    "# -----------------------------------------------------------------------------\n",
    "import torch\n",
    "from trimesh.transformations import euler_matrix\n",
    "\n",
    "\n",
    "def get_rays(H, W, focal=300.0):\n",
    "    i, j = torch.meshgrid(\n",
    "        torch.linspace(0, W - 1, W),\n",
    "        torch.linspace(0, H - 1, H),\n",
    "        indexing=\"xy\",\n",
    "    )\n",
    "    dirs = torch.stack(\n",
    "        [(i - W / 2) / focal, -(j - H / 2) / focal, -torch.ones_like(i)],\n",
    "        dim=-1,\n",
    "    )\n",
    "    dirs = dirs / torch.norm(dirs, dim=-1, keepdim=True)\n",
    "    orig = torch.zeros_like(dirs)\n",
    "    return orig.reshape(-1, 3), dirs.reshape(-1, 3)\n",
    "\n",
    "def rotate_rays(o, d, angles_deg):\n",
    "    \"\"\"\n",
    "    angles_deg: tensor([rx, ry, rz]) in degrees, 'sxyz' convention\n",
    "    \"\"\"\n",
    "    # → in radians für euler_matrix\n",
    "    ang = angles_deg * np.pi / 180.0\n",
    "    R4 = euler_matrix(float(ang[0]), float(ang[1]), float(ang[2]), \"sxyz\")\n",
    "    R = torch.from_numpy(R4[:3, :3]).float().to(o.device)\n",
    "    return (R @ o.T).T, (R @ d.T).T\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. Weighted Sampling\n",
    "# -----------------------------------------------------------------------------\n",
    "def sample_rays_weighted(rays_o, rays_d, rgb, mask, original_shape, batch_size=1024):\n",
    "    H, W = original_shape\n",
    "    ppv = H * W\n",
    "    weights = []\n",
    "    # two views\n",
    "    for v in range(2):\n",
    "        m = mask[v * ppv : (v + 1) * ppv].reshape(H, W)\n",
    "        k = (\n",
    "            torch.tensor(\n",
    "                [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], device=m.device\n",
    "            ).float()\n",
    "            / 8\n",
    "        )\n",
    "        edges = torch.abs(\n",
    "            torch.nn.functional.conv2d(\n",
    "                m.unsqueeze(0).unsqueeze(0), k.unsqueeze(0).unsqueeze(0), padding=1\n",
    "            )\n",
    "        ).reshape(H, W)\n",
    "        w = (\n",
    "            edges.reshape(-1)\n",
    "            + 0.1\n",
    "            + (mask[v * ppv : (v + 1) * ppv] > 0.5).float() * 2.0\n",
    "        )\n",
    "        weights.append(w)\n",
    "    p = torch.cat(weights)\n",
    "    p /= p.sum()\n",
    "    idx = torch.multinomial(p, batch_size, replacement=True)\n",
    "    return rays_o[idx], rays_d[idx], rgb[idx], mask[idx]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7. Debug & 8. Marching Cubes, 9. Chamfer same as before\n",
    "# ... (omitted for brevity; copy your existing debug_render, debug_compare, extract_3d_from_nerf, chamfer_distance)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 10. Training\n",
    "# -----------------------------------------------------------------------------\n",
    "def train_nerf(\n",
    "    model,\n",
    "    rays_o_all,\n",
    "    rays_d_all,\n",
    "    target_pixels_all,\n",
    "    mask_all,\n",
    "    image_shape,\n",
    "    num_iterations=8000,\n",
    "    \n",
    "    device=None,\n",
    "    near=0.5,\n",
    "    far=1.5,\n",
    "    sigma_scale=2.0,\n",
    "    debug_interval=1000,\n",
    "    out_dir=\"debug_renders\",\n",
    "):\n",
    "    H, W = image_shape\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "    opt = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    sch = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        opt, mode=\"min\", factor=0.5, patience=300\n",
    "    )\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    front_o = canonical_rays[\"front_o\"].to(device)\n",
    "    front_d = canonical_rays[\"front_d\"].to(device)\n",
    "    side_o  = canonical_rays[\"side_o\"].to(device)\n",
    "    side_d  = canonical_rays[\"side_d\"].to(device)\n",
    "\n",
    "    # strong prior lambdas\n",
    "    lambda_sil = 4.0\n",
    "    lambda_shape = 3.0\n",
    "    lambda_density = 0.5\n",
    "    lambda_smooth = 0.5\n",
    "    lambda_radial = 3.0\n",
    "    lambda_sym = 5.0\n",
    "\n",
    "    best = 1e9\n",
    "    for i in trange(num_iterations, desc=\"Training\"):\n",
    "        opt.zero_grad()\n",
    "        ro, rd, rgbB, mB = sample_rays_weighted(\n",
    "            rays_o_all, rays_d_all, target_pixels_all, mask_all, (H, W), 1024\n",
    "        )\n",
    "        with torch.cuda.amp.autocast():\n",
    "            rays_o_front = front_o + t_front.unsqueeze(0)\n",
    "            rays_o_side  = side_o  + t_side .unsqueeze(0)\n",
    "            rays_o_all   = torch.cat([rays_o_front, rays_o_side], dim=0)\n",
    "            rays_d_all   = torch.cat([front_d, side_d], dim=0)\n",
    "\n",
    "            # 2) daraus dann Rays sample’n\n",
    "            rays_o_batch, rays_d_batch, rgb_batch, mask_batch = sample_rays_weighted(\n",
    "                rays_o_all, rays_d_all, target_pixels_all, mask_all,\n",
    "                original_shape=(H,W), batch_size=1024\n",
    "            )\n",
    "            rgb_map, alpha_map = render_rays(model, ro, rd, near, far, 64, sigma_scale)\n",
    "            Lp = torch.mean((rgb_map - rgbB) ** 2)\n",
    "            Ls = silhouette_loss(alpha_map, mB)\n",
    "            Lh = spherical_prior_loss(model, device=device)\n",
    "            Ld = foreground_density_loss(alpha_map, mB)\n",
    "            Lsm = smoothness_prior_loss(model, device=device)\n",
    "            Lr = radial_profile_loss(model, device=device)\n",
    "            Lsy = symmetry_loss(model, device=device)\n",
    "            loss = (\n",
    "                Lp\n",
    "                + lambda_sil * Ls\n",
    "                + lambda_shape * Lh\n",
    "                + lambda_density * Ld\n",
    "                + lambda_smooth * Lsm\n",
    "                + lambda_radial * Lr\n",
    "                + lambda_sym * Lsy\n",
    "            )\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        sch.step(loss)\n",
    "        if (i + 1) % 200 == 0 and loss < best:\n",
    "            best = loss\n",
    "            torch.save(model.state_dict(), \"nerf_best.pth\")\n",
    "        if (i + 1) % debug_interval == 0:\n",
    "            # debug_render calls...\n",
    "            pass\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 11. Main\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device:\", dev)\n",
    "    tf = transforms.ToTensor()\n",
    "    dataset, train_ids, _ = get_train_test_split(image_transforms=tf, device=dev)\n",
    "    (l_img, r_img), pts, rot, vox = dataset[train_ids[3]]\n",
    "    # plot the two images\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(l_img.permute(1, 2, 0).cpu(), interpolation=\"nearest\")\n",
    "    plt.title(\"Left Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(r_img.permute(1, 2, 0).cpu(), interpolation=\"nearest\")\n",
    "    plt.title(\"Right Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    # prepare two views as before\n",
    "    H, W = l_img.shape[1], l_img.shape[2]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 1) Kanonische Front-Rays\n",
    "    rays_o_f, rays_d_f = get_rays(H, W, focal=300.0)\n",
    "\n",
    "    # 2) Kanonische Side-Rays: 90° Yaw um Y‑Achse\n",
    "    yaw90 = torch.tensor([0.0, 90.0, 0.0], device=device)\n",
    "    rays_o_s, rays_d_s = rotate_rays(rays_o_f, rays_d_f, yaw90)\n",
    "\n",
    "    # 3) Auf die Sample-Rotation anwenden (deine rot aus dem Dataset)\n",
    "    rot = torch.tensor(rot, device=device)  # z.B. tensor([rx, ry, rz])\n",
    "    rays_o_front, rays_d_front = rotate_rays(rays_o_f, rays_d_f, rot)\n",
    "    rays_o_side,  rays_d_side  = rotate_rays(rays_o_s, rays_d_s, rot)\n",
    "\n",
    "    # 4) Beide Views zusammenpacken\n",
    "    rays_o_all = torch.cat([rays_o_front, rays_o_side], dim=0).to(device)\n",
    "    rays_d_all = torch.cat([rays_d_front, rays_d_side], dim=0).to(device)\n",
    "    # target_pixels_all, mask_all built similarly\n",
    "    model = NeRF().to(dev)\n",
    "    model = train_nerf(\n",
    "        model, rays_o_all, rays_d_all, target_pixels_all, mask_all, (H, W), device=dev\n",
    "    )\n",
    "    # extract mesh & chamfer\n",
    "\n",
    "    print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
