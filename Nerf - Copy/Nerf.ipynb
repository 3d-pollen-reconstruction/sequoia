{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257860de-71ad-4386-88bd-fc945e3bc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset_org import get_rays\n",
    "from rendering import rendering\n",
    "from model import Voxels, Nerf\n",
    "from ml_helpers import training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922e325-8976-4a36-88aa-908cbe4d3953",
   "metadata": {},
   "source": [
    "# Camera / Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e62ab8-9524-48b6-a646-01b27c9a3fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched o.shape=(90, 160000, 3), dims=3\n",
      "Warm-up crop: 45×80000, total rays=3600000\n",
      "Fetched test_o.shape=(10, 160000, 3), dims=3\n",
      "Train rays=14400000, Test rays=1600000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Batch size\n",
    "batch_size = 1024\n",
    "\n",
    "# Fetch rays (might be [N,H,W,3], [H,W,3], or already flattened [M,3])\n",
    "o, d, target_px_values = get_rays(datapath='pollen_100', mode='train')\n",
    "\n",
    "print(f\"Fetched o.shape={o.shape}, dims={o.ndim}\")\n",
    "\n",
    "# Dynamically flatten for training\n",
    "o_flat, d_flat, t_flat = None, None, None\n",
    "if o.ndim == 4:\n",
    "    N, H, W, C = o.shape\n",
    "    o_flat = torch.from_numpy(o).reshape(-1, C).float()\n",
    "    d_flat = torch.from_numpy(d).reshape(-1, C).float()\n",
    "    t_flat = torch.from_numpy(target_px_values).reshape(-1, C).float()\n",
    "elif o.ndim == 3:\n",
    "    H, W, C = o.shape\n",
    "    o_flat = torch.from_numpy(o).reshape(-1, C).float()\n",
    "    d_flat = torch.from_numpy(d).reshape(-1, C).float()\n",
    "    t_flat = torch.from_numpy(target_px_values).reshape(-1, C).float()\n",
    "elif o.ndim == 2:\n",
    "    o_flat = torch.from_numpy(o).float()\n",
    "    d_flat = torch.from_numpy(d).float()\n",
    "    t_flat = torch.from_numpy(target_px_values).float()\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported o.ndim={o.ndim}\")\n",
    "\n",
    "# Training DataLoader\n",
    "dataset = torch.cat((o_flat, d_flat, t_flat), dim=1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Warm-up loader: center-crop half the spatial dims if available\n",
    "if o.ndim >= 3:\n",
    "    crop_frac = 0.5\n",
    "    crop_h = int((H if o.ndim==4 else H) * crop_frac)\n",
    "    crop_w = int((W if o.ndim==4 else W) * crop_frac)\n",
    "    start_h = ((H if o.ndim==4 else H) - crop_h) // 2\n",
    "    start_w = ((W if o.ndim==4 else W) - crop_w) // 2\n",
    "\n",
    "    if o.ndim == 4:\n",
    "        o_crop = o[:, start_h:start_h+crop_h, start_w:start_w+crop_w, :]\n",
    "        d_crop = d[:, start_h:start_h+crop_h, start_w:start_w+crop_w, :]\n",
    "        t_crop = target_px_values[:, start_h:start_h+crop_h, start_w:start_w+crop_w, :]\n",
    "    else:\n",
    "        o_crop = o[start_h:start_h+crop_h, start_w:start_w+crop_w, :]\n",
    "        d_crop = d[start_h:start_h+crop_h, start_w:start_w+crop_w, :]\n",
    "        t_crop = target_px_values[start_h:start_h+crop_h, start_w:start_w+crop_w, :]\n",
    "\n",
    "    C_crop = o_crop.shape[-1]\n",
    "    o_crop_flat = torch.from_numpy(o_crop).reshape(-1, C_crop).float()\n",
    "    d_crop_flat = torch.from_numpy(d_crop).reshape(-1, C_crop).float()\n",
    "    t_crop_flat = torch.from_numpy(t_crop).reshape(-1, C_crop).float()\n",
    "\n",
    "    warmup_dataset = torch.cat((o_crop_flat, d_crop_flat, t_crop_flat), dim=1)\n",
    "    dataloader_warmup = DataLoader(warmup_dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(f\"Warm-up crop: {crop_h}×{crop_w}, total rays={len(warmup_dataset)}\")\n",
    "else:\n",
    "    dataloader_warmup = None\n",
    "    print(\"Skipping warm-up loader: spatial dims unknown\")\n",
    "\n",
    "# Test loader\n",
    "test_o, test_d, test_t = get_rays('pollen_100', mode='test')\n",
    "print(f\"Fetched test_o.shape={test_o.shape}, dims={test_o.ndim}\")\n",
    "\n",
    "# Flatten test similarly\n",
    "t_flatest, d_flatest, t_flatest = None, None, None\n",
    "if test_o.ndim >= 3:\n",
    "    C_test = test_o.shape[-1]\n",
    "    t_flatest = torch.from_numpy(test_o.reshape(-1, C_test)).float()\n",
    "    d_flatest = torch.from_numpy(test_d.reshape(-1, C_test)).float()\n",
    "    t_flatest = torch.from_numpy(test_t.reshape(-1, C_test)).float()\n",
    "else:\n",
    "    t_flatest = torch.from_numpy(test_o).float()\n",
    "    d_flatest = torch.from_numpy(test_d).float()\n",
    "    t_flatest = torch.from_numpy(test_t).float()\n",
    "\n",
    "test_dataset = torch.cat((t_flatest, d_flatest, t_flatest), dim=1)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train rays={len(dataset)}, Test rays={len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc6284-ff38-4a9d-a914-7cd8ff9163fb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd96eec-e258-469d-8781-da1dc2bd1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "tn, tf           = 8.0, 12.0\n",
    "nb_epochs        = 10\n",
    "lr, gamma        = 1e-3, 0.5\n",
    "nb_bins          = 100\n",
    "\n",
    "model     = Nerf(hidden_dim=128).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[5, 10], gamma=gamma\n",
    ")\n",
    "\n",
    "# --- Warm-up (1 epoch on the center-crop loader) ---\n",
    "batch_wu, epoch_wu, psnr_wu = training(\n",
    "    model, optimizer, scheduler,\n",
    "    tn, tf, nb_bins,\n",
    "    nb_epochs=1,\n",
    "    data_loader=dataloader_warmup,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Plot warm-up per-batch loss\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(batch_wu, color='C2')\n",
    "plt.title(\"Warm-up: Per-Batch MSE Loss\")\n",
    "plt.xlabel(\"Batch #\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "\n",
    "# --- Main training (full data) ---\n",
    "batch_tr, epoch_tr, psnr_tr = training(\n",
    "    model, optimizer, scheduler,\n",
    "    tn, tf, nb_bins,\n",
    "    nb_epochs=nb_epochs,\n",
    "    data_loader=dataloader,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Plot main per-batch loss\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(batch_tr, color='C0')\n",
    "plt.title(\"Training: Per-Batch MSE Loss\")\n",
    "plt.xlabel(\"Batch #\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "\n",
    "# Plot per-epoch averages & PSNR (combined warm-up + main)\n",
    "all_epoch_losses = epoch_wu + epoch_tr\n",
    "all_epoch_psnrs  = psnr_wu  + psnr_tr\n",
    "epochs = list(range(1, 1 + len(all_epoch_losses)))\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8,4))\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(epochs, all_epoch_losses, '-o', color='C0', label='Avg MSE Loss')\n",
    "ax2.plot(epochs, all_epoch_psnrs, '--s', color='C1', label='Avg PSNR (dB)')\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Avg MSE Loss', color='C0')\n",
    "ax2.set_ylabel('Avg PSNR (dB)', color='C1')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.title(\"Epoch-wise Metrics (Warm-up + Training)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2ceae-86b6-4d6d-aafe-ac3627807f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_nerf3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
